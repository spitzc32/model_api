{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spitzc32/model_api/blob/master/ModelTrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yLoZtjkgUb8",
        "outputId": "919047d8-b029-48d1-c99b-2a0f0609b2bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair\n",
            "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
            "\u001b[K     |████████████████████████████████| 401 kB 32.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 64.4 MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.64.0)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 64.3 MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 57.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from flair) (8.14.0)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.12.1+cu113)\n",
            "Collecting hyperopt>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 56.7 MB/s \n",
            "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2022.6.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.10)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 53.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting conllu>=4.0\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 70.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.5.0)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (6.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Building wheels for collected packages: mpld3, overrides, sqlitedict, langdetect, pptree, wikipedia-api\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=75da733f36d4c53f89c3cece29a2761d5328e0d3057ad1c566206dcd82995b30\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=58a97ea9d9d65adf38c7c7109795a9c86eb85ff60ae055b249098ed6ac8e5548\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=1f6fa7a88d2c67c7346f45b5a3553b0f29c5e4e007a19874468435a543a44731\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/dd/2e/0ed4a25cb73fc30c7ea8d10b50acb7226175736067e40a7ea3\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=4ef9a977f0d770231f040d7e7a0c9d0564bed7147b118c4df242908f55735e93\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=dfb81a661ed289a6789fb75d9dd93553abfd9e73b779daff9dd85f886c5369e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e8/7d/a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=a000830eb5cdc565b6f355e0ff0ee5db602e2f3b000c01724eb32d4dd9c1422b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built mpld3 overrides sqlitedict langdetect pptree wikipedia-api\n",
            "Installing collected packages: requests, importlib-metadata, tokenizers, sentencepiece, py4j, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, pptree, mpld3, langdetect, konoha, janome, hyperopt, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.12.0\n",
            "    Uninstalling importlib-metadata-4.12.0:\n",
            "      Successfully uninstalled importlib-metadata-4.12.0\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.4.1 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n",
            "gym 0.25.1 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.5.2 deprecated-1.2.13 flair-0.11.3 ftfy-6.1.1 huggingface-hub-0.9.1 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.7 requests-2.28.1 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.0.0 tokenizers-0.12.1 transformers-4.21.2 wikipedia-api-0.5.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install flair\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ryy97utAgQi5"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "def get_spans_from_bio(bioes_tags, bioes_scores=None):\n",
        "    # add a dummy \"O\" to close final prediction\n",
        "    bioes_tags.append(\"O\")\n",
        "    # return complex list\n",
        "    found_spans = []\n",
        "    # internal variables\n",
        "    current_tag_weights: Dict[str, float] = defaultdict(lambda: 0.0)\n",
        "    previous_tag = \"O-\"\n",
        "    current_span = []\n",
        "    current_span_scores = []\n",
        "    for idx, bioes_tag in enumerate(bioes_tags):\n",
        "\n",
        "        # non-set tags are OUT tags\n",
        "        if bioes_tag == \"\" or bioes_tag == \"O\" or bioes_tag == \"_\":\n",
        "            bioes_tag = \"O-\"\n",
        "\n",
        "        # anything that is not OUT is IN\n",
        "        in_span = False if bioes_tag == \"O-\" else True\n",
        "\n",
        "        # does this prediction start a new span?\n",
        "        starts_new_span = False\n",
        "\n",
        "        # begin and single tags start new spans\n",
        "        if bioes_tag[0:2] in [\"B-\", \"S-\"]:\n",
        "            starts_new_span = True\n",
        "\n",
        "        # in IOB format, an I tag starts a span if it follows an O or is a different span\n",
        "        if bioes_tag[0:2] == \"I-\" and previous_tag[2:] != bioes_tag[2:]:\n",
        "            starts_new_span = True\n",
        "\n",
        "        # single tags that change prediction start new spans\n",
        "        if bioes_tag[0:2] in [\"S-\"] and previous_tag[2:] != bioes_tag[2:]:\n",
        "            starts_new_span = True\n",
        "\n",
        "        # if an existing span is ended (either by reaching O or starting a new span)\n",
        "        if (starts_new_span or not in_span) and len(current_span) > 0:\n",
        "            # determine score and value\n",
        "            span_score = sum(current_span_scores) / len(current_span_scores)\n",
        "            span_value = sorted(current_tag_weights.items(), key=lambda k_v: k_v[1], reverse=True)[0][0]\n",
        "\n",
        "            # append to result list\n",
        "            found_spans.append((current_span, span_score, span_value))\n",
        "\n",
        "            # reset for-loop variables for new span\n",
        "            current_span = []\n",
        "            current_span_scores = []\n",
        "            current_tag_weights = defaultdict(lambda: 0.0)\n",
        "\n",
        "        if in_span:\n",
        "            current_span.append(idx)\n",
        "            current_span_scores.append(bioes_scores[idx] if bioes_scores else 1.0)\n",
        "            weight = 1.1 if starts_new_span else 1.0\n",
        "            current_tag_weights[bioes_tag[2:]] += weight\n",
        "\n",
        "        # remember previous tag\n",
        "        previous_tag = bioes_tag\n",
        "\n",
        "    return found_spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y0XY3bX2gz8m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import flair\n",
        "\n",
        "START_TAG: str = \"<START>\"\n",
        "STOP_TAG: str = \"<STOP>\"\n",
        "\n",
        "\n",
        "class CRF(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Conditional Random Field Implementation according to sgrvinod (https://github.com/sgrvinod).\n",
        "    Classifier which predicts single tag / class / label for given word based on not just the word,\n",
        "    but also on previous seen annotations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tag_dictionary, tagset_size: int, init_from_state_dict: bool):\n",
        "        \"\"\"\n",
        "        :param tag_dictionary: tag dictionary in order to find ID for start and stop tags\n",
        "        :param tagset_size: number of tag from tag dictionary\n",
        "        :param init_from_state_dict: whether we load pretrained model from state dict\n",
        "        \"\"\"\n",
        "        super(CRF, self).__init__()\n",
        "\n",
        "        self.tagset_size = tagset_size\n",
        "        # Transitions are used in the following way: transitions[to, from].\n",
        "        self.transitions = torch.nn.Parameter(torch.randn(tagset_size, tagset_size))\n",
        "        # If we are not using a pretrained model and train a fresh one, we need to set transitions from any tag\n",
        "        # to START-tag and from STOP-tag to any other tag to -10000.\n",
        "        if not init_from_state_dict:\n",
        "            self.transitions.detach()[tag_dictionary.get_idx_for_item(START_TAG), :] = -10000\n",
        "\n",
        "            self.transitions.detach()[:, tag_dictionary.get_idx_for_item(STOP_TAG)] = -10000\n",
        "        self.to(flair.device)\n",
        "\n",
        "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward propagation of Conditional Random Field.\n",
        "        :param features: output from RNN / Linear layer in shape (batch size, seq len, hidden size)\n",
        "        :return: CRF scores (emission scores for each token + transitions prob from previous state) in\n",
        "        shape (batch_size, seq len, tagset size, tagset size)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = features.size()[:2]\n",
        "\n",
        "        emission_scores = features\n",
        "        emission_scores = emission_scores.unsqueeze(-1).expand(batch_size, seq_len, self.tagset_size, self.tagset_size)\n",
        "\n",
        "        crf_scores = emission_scores + self.transitions.unsqueeze(0).unsqueeze(0)\n",
        "        return crf_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AftIFVXXq0Hj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import flair\n",
        "\n",
        "class LSTM(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Simple LSTM Implementation that returns the features used for (1)CRF and (2)Span Classifier\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, rnn_layers: int, hidden_size: int, bidirectional: bool, rnn_input_dim: int,):\n",
        "        \"\"\"\n",
        "        :param tag_dictionary: tag dictionary in order to find ID for start and stop tags\n",
        "        :param tagset_size: number of tag from tag dictionary\n",
        "        :param init_from_state_dict: whether we load pretrained model from state dict\n",
        "        \"\"\"\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn_input_dim = rnn_input_dim\n",
        "        self.num_layers = rnn_layers\n",
        "        self.dropout = 0.0 if rnn_layers == 1 else 0.5\n",
        "        self.bidirectional = bidirectional\n",
        "        self.batch_first = True\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            self.rnn_input_dim,\n",
        "            self.hidden_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=self.dropout,\n",
        "            bidirectional=self.bidirectional,\n",
        "            batch_first=self.batch_first,\n",
        "        )\n",
        "\n",
        "        self.to(flair.device)\n",
        "    \n",
        "    def forward(self, sentence_tensor: torch.Tensor, sorted_lengths: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward propagation of LSTM Model by packing the tensors.\n",
        "        :param features: output from RNN / Linear layer in shape (batch size, seq len, hidden size)\n",
        "        :return: CRF scores (emission scores for each token + transitions prob from previous state) in\n",
        "        shape (batch_size, seq len, tagset size, tagset size)\n",
        "        \"\"\"\n",
        "        packed = pack_padded_sequence(sentence_tensor, sorted_lengths, batch_first=True, enforce_sorted=False)\n",
        "        rnn_output, hidden = self.lstm(packed)\n",
        "        sentence_tensor, output_lengths = pad_packed_sequence(rnn_output, batch_first=True)\n",
        "\n",
        "        return sentence_tensor, output_lengths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E95ayW9IghN7"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn\n",
        "from torch.nn.functional import softmax\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "import flair\n",
        "from flair.data import Dictionary, Label, List, Sentence\n",
        "\n",
        "START_TAG: str = \"<START>\"\n",
        "STOP_TAG: str = \"<STOP>\"\n",
        "\n",
        "\n",
        "class ViterbiLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Calculates the loss for each sequence up to its length t.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tag_dictionary: Dictionary):\n",
        "        \"\"\"\n",
        "        :param tag_dictionary: tag_dictionary of task\n",
        "        \"\"\"\n",
        "        super(ViterbiLoss, self).__init__()\n",
        "        self.tag_dictionary = tag_dictionary\n",
        "        self.tagset_size = len(tag_dictionary)\n",
        "        self.start_tag = tag_dictionary.get_idx_for_item(START_TAG)\n",
        "        self.stop_tag = tag_dictionary.get_idx_for_item(STOP_TAG)\n",
        "\n",
        "    def forward(self, features_tuple: tuple, targets: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward propagation of Viterbi Loss\n",
        "        :param features_tuple: CRF scores from forward method in shape (batch size, seq len, tagset size, tagset size),\n",
        "            lengths of sentences in batch, transitions from CRF\n",
        "        :param targets: true tags for sentences which will be converted to matrix indices.\n",
        "        :return: average Viterbi Loss over batch size\n",
        "        \"\"\"\n",
        "        features, lengths, transitions = features_tuple\n",
        "\n",
        "        batch_size = features.size(0)\n",
        "        seq_len = features.size(1)\n",
        "\n",
        "        targets, targets_matrix_indices = self._format_targets(targets, lengths)\n",
        "        targets_matrix_indices = torch.tensor(targets_matrix_indices, dtype=torch.long).unsqueeze(2).to(flair.device)\n",
        "\n",
        "        # scores_at_targets[range(features.shape[0]), lengths.values -1]\n",
        "        # Squeeze crf scores matrices in 1-dim shape and gather scores at targets by matrix indices\n",
        "        scores_at_targets = torch.gather(features.view(batch_size, seq_len, -1), 2, targets_matrix_indices)\n",
        "        scores_at_targets = pack_padded_sequence(scores_at_targets, lengths, batch_first=True)[0]\n",
        "        transitions_to_stop = transitions[\n",
        "            np.repeat(self.stop_tag, features.shape[0]),\n",
        "            [target[length - 1] for target, length in zip(targets, lengths)],\n",
        "        ]\n",
        "        gold_score = scores_at_targets.sum() + transitions_to_stop.sum()\n",
        "\n",
        "        scores_upto_t = torch.zeros(batch_size, self.tagset_size, device=flair.device)\n",
        "\n",
        "        for t in range(max(lengths)):\n",
        "            batch_size_t = sum(\n",
        "                [length > t for length in lengths]\n",
        "            )  # since batch is ordered, we can save computation time by reducing our effective batch_size\n",
        "\n",
        "            if t == 0:\n",
        "                # Initially, get scores from <start> tag to all other tags\n",
        "                scores_upto_t[:batch_size_t] = (\n",
        "                    scores_upto_t[:batch_size_t] + features[:batch_size_t, t, :, self.start_tag]\n",
        "                )\n",
        "            else:\n",
        "                # We add scores at current timestep to scores accumulated up to previous timestep, and log-sum-exp\n",
        "                # Remember, the cur_tag of the previous timestep is the prev_tag of this timestep\n",
        "                scores_upto_t[:batch_size_t] = self._log_sum_exp(\n",
        "                    features[:batch_size_t, t, :, :] + scores_upto_t[:batch_size_t].unsqueeze(1), dim=2\n",
        "                )\n",
        "\n",
        "        all_paths_scores = self._log_sum_exp(scores_upto_t + transitions[self.stop_tag].unsqueeze(0), dim=1).sum()\n",
        "\n",
        "        viterbi_loss = all_paths_scores - gold_score\n",
        "\n",
        "        return viterbi_loss\n",
        "\n",
        "    @staticmethod\n",
        "    def _log_sum_exp(tensor, dim):\n",
        "        \"\"\"\n",
        "        Calculates the log-sum-exponent of a tensor's dimension in a numerically stable way.\n",
        "        :param tensor: tensor\n",
        "        :param dim: dimension to calculate log-sum-exp of\n",
        "        :return: log-sum-exp\n",
        "        \"\"\"\n",
        "        m, _ = torch.max(tensor, dim)\n",
        "        m_expanded = m.unsqueeze(dim).expand_as(tensor)\n",
        "        return m + torch.log(torch.sum(torch.exp(tensor - m_expanded), dim))\n",
        "\n",
        "    def _format_targets(self, targets: torch.Tensor, lengths: torch.IntTensor):\n",
        "        \"\"\"\n",
        "        Formats targets into matrix indices.\n",
        "        CRF scores contain per sentence, per token a (tagset_size x tagset_size) matrix, containing emission score for\n",
        "            token j + transition prob from previous token i. Means, if we think of our rows as \"to tag\" and our columns\n",
        "            as \"from tag\", the matrix in cell [10,5] would contain the emission score for tag 10 + transition score\n",
        "            from previous tag 5 and could directly be addressed through the 1-dim indices (10 + tagset_size * 5) = 70,\n",
        "            if our tagset consists of 12 tags.\n",
        "        :param targets: targets as in tag dictionary\n",
        "        :param lengths: lengths of sentences in batch\n",
        "        \"\"\"\n",
        "        targets_per_sentence = []\n",
        "\n",
        "        targets_list = targets.tolist()\n",
        "        for cut in lengths:\n",
        "            targets_per_sentence.append(targets_list[:cut])\n",
        "            targets_list = targets_list[cut:]\n",
        "\n",
        "        for t in targets_per_sentence:\n",
        "            t += [self.tag_dictionary.get_idx_for_item(STOP_TAG)] * (int(lengths.max().item()) - len(t))\n",
        "\n",
        "        matrix_indices = list(\n",
        "            map(\n",
        "                lambda s: [self.tag_dictionary.get_idx_for_item(START_TAG) + (s[0] * self.tagset_size)]\n",
        "                + [s[i] + (s[i + 1] * self.tagset_size) for i in range(0, len(s) - 1)],\n",
        "                targets_per_sentence,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return targets_per_sentence, matrix_indices\n",
        "\n",
        "\n",
        "class ViterbiDecoder:\n",
        "    \"\"\"\n",
        "    Decodes a given sequence using the Viterbi algorithm.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tag_dictionary: Dictionary):\n",
        "        \"\"\"\n",
        "        :param tag_dictionary: Dictionary of tags for sequence labeling task\n",
        "        \"\"\"\n",
        "        self.tag_dictionary = tag_dictionary\n",
        "        self.tagset_size = len(tag_dictionary)\n",
        "        self.start_tag = tag_dictionary.get_idx_for_item(START_TAG)\n",
        "        self.stop_tag = tag_dictionary.get_idx_for_item(STOP_TAG)\n",
        "\n",
        "    def decode(\n",
        "        self, features_tuple: tuple, probabilities_for_all_classes: bool, sentences: List[Sentence]\n",
        "    ) -> Tuple[List, List]:\n",
        "        \"\"\"\n",
        "        Decoding function returning the most likely sequence of tags.\n",
        "        :param features_tuple: CRF scores from forward method in shape (batch size, seq len, tagset size, tagset size),\n",
        "            lengths of sentence in batch, transitions of CRF\n",
        "        :param probabilities_for_all_classes: whether to return probabilities for all tags\n",
        "        :return: decoded sequences\n",
        "        \"\"\"\n",
        "        features, lengths, transitions = features_tuple\n",
        "        all_tags = []\n",
        "\n",
        "        batch_size = features.size(0)\n",
        "        seq_len = features.size(1)\n",
        "\n",
        "        # Create a tensor to hold accumulated sequence scores at each current tag\n",
        "        scores_upto_t = torch.zeros(batch_size, seq_len + 1, self.tagset_size).to(flair.device)\n",
        "        # Create a tensor to hold back-pointers\n",
        "        # i.e., indices of the previous_tag that corresponds to maximum accumulated score at current tag\n",
        "        # Let pads be the <end> tag index, since that was the last tag in the decoded sequence\n",
        "        backpointers = (\n",
        "            torch.ones((batch_size, seq_len + 1, self.tagset_size), dtype=torch.long, device=flair.device)\n",
        "            * self.stop_tag\n",
        "        )\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            batch_size_t = sum([length > t for length in lengths])  # effective batch size (sans pads) at this timestep\n",
        "            terminates = [i for i, length in enumerate(lengths) if length == t + 1]\n",
        "\n",
        "            if t == 0:\n",
        "                scores_upto_t[:batch_size_t, t] = features[:batch_size_t, t, :, self.start_tag]\n",
        "                backpointers[:batch_size_t, t, :] = (\n",
        "                    torch.ones((batch_size_t, self.tagset_size), dtype=torch.long) * self.start_tag\n",
        "                )\n",
        "            else:\n",
        "                # We add scores at current timestep to scores accumulated up to previous timestep, and\n",
        "                # choose the previous timestep that corresponds to the max. accumulated score for each current timestep\n",
        "                scores_upto_t[:batch_size_t, t], backpointers[:batch_size_t, t, :] = torch.max(\n",
        "                    features[:batch_size_t, t, :, :] + scores_upto_t[:batch_size_t, t - 1].unsqueeze(1), dim=2\n",
        "                )\n",
        "\n",
        "            # If sentence is over, add transition to STOP-tag\n",
        "            if terminates:\n",
        "                scores_upto_t[terminates, t + 1], backpointers[terminates, t + 1, :] = torch.max(\n",
        "                    scores_upto_t[terminates, t].unsqueeze(1) + transitions[self.stop_tag].unsqueeze(0), dim=2\n",
        "                )\n",
        "\n",
        "        # Decode/trace best path backwards\n",
        "        decoded = torch.zeros((batch_size, backpointers.size(1)), dtype=torch.long, device=flair.device)\n",
        "        pointer = torch.ones((batch_size, 1), dtype=torch.long, device=flair.device) * self.stop_tag\n",
        "\n",
        "        for t in list(reversed(range(backpointers.size(1)))):\n",
        "            decoded[:, t] = torch.gather(backpointers[:, t, :], 1, pointer).squeeze(1)\n",
        "            pointer = decoded[:, t].unsqueeze(1)\n",
        "\n",
        "        # Sanity check\n",
        "        assert torch.equal(\n",
        "            decoded[:, 0], torch.ones((batch_size), dtype=torch.long, device=flair.device) * self.start_tag\n",
        "        )\n",
        "\n",
        "        # remove start-tag and backscore to stop-tag\n",
        "        scores_upto_t = scores_upto_t[:, :-1, :]\n",
        "        decoded = decoded[:, 1:]\n",
        "\n",
        "        # Max + Softmax to get confidence score for predicted label and append label to each token\n",
        "        scores = softmax(scores_upto_t, dim=2)\n",
        "        confidences = torch.max(scores, dim=2)\n",
        "\n",
        "        tags = []\n",
        "        for tag_seq, tag_seq_conf, length_seq in zip(decoded, confidences.values, lengths):\n",
        "            tags.append(\n",
        "                [\n",
        "                    (self.tag_dictionary.get_item_for_index(tag), conf.item())\n",
        "                    for tag, conf in list(zip(tag_seq, tag_seq_conf))[:length_seq]\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        if probabilities_for_all_classes:\n",
        "            all_tags = self._all_scores_for_token(scores.cpu(), lengths, sentences)\n",
        "\n",
        "        return tags, all_tags\n",
        "\n",
        "    def _all_scores_for_token(self, scores: torch.Tensor, lengths: torch.IntTensor, sentences: List[Sentence]):\n",
        "        \"\"\"\n",
        "        Returns all scores for each tag in tag dictionary.\n",
        "        :param scores: Scores for current sentence.\n",
        "        \"\"\"\n",
        "        scores = scores.numpy()\n",
        "        prob_tags_per_sentence = []\n",
        "        for scores_sentence, length, sentence in zip(scores, lengths, sentences):\n",
        "            scores_sentence = scores_sentence[:length]\n",
        "            prob_tags_per_sentence.append(\n",
        "                [\n",
        "                    [\n",
        "                        Label(token, self.tag_dictionary.get_item_for_index(score_id), score)\n",
        "                        for score_id, score in enumerate(score_dist)\n",
        "                    ]\n",
        "                    for score_dist, token in zip(scores_sentence, sentence)\n",
        "                ]\n",
        "            )\n",
        "        return prob_tags_per_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4MCg4pQh7jnl"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Optional\n",
        "from flair.data import _PartOfSentence, DataPoint, Label\n",
        "\n",
        "class Token(_PartOfSentence):\n",
        "    \"\"\"\n",
        "    This class represents one word in a tokenized sentence. Each token may have any number of tags. It may also point\n",
        "    to its head in a dependency tree.\n",
        "\n",
        "    :param text: Single text(Token) from the sequence\n",
        "    :param head_id: the location of the text (For Document)\n",
        "    :param whitespace_after: if token has whitespace\n",
        "    :param start_position: what character number in document does this token start?\n",
        "    :param sentence: If token belongs to sentence, indicate here which var it belongs to\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        text: str,\n",
        "        head_id: int = None,\n",
        "        whitespace_after: int = 1,\n",
        "        start_position: int = 0,\n",
        "        sentence=None,\n",
        "    ):\n",
        "        super().__init__(sentence=sentence)\n",
        "\n",
        "        self.form: str = text\n",
        "        self._internal_index: Optional[int] = None\n",
        "        self.head_id: Optional[int] = head_id\n",
        "        self.whitespace_after: int = whitespace_after\n",
        "\n",
        "        self.start_pos = start_position\n",
        "        self.end_pos = start_position + len(text)\n",
        "\n",
        "        self._embeddings: Dict = {}\n",
        "        self.tags_proba_dist: Dict[str, List[Label]] = {}\n",
        "\n",
        "    @property\n",
        "    def idx(self) -> int:\n",
        "        if isinstance(self._internal_index, int):\n",
        "            return self._internal_index\n",
        "        else:\n",
        "            raise ValueError\n",
        "\n",
        "    @property\n",
        "    def text(self):\n",
        "        return self.form\n",
        "\n",
        "    @property\n",
        "    def unlabeled_identifier(self) -> str:\n",
        "        return f'Token[{self.idx-1}]: \"{self.text}\"'\n",
        "\n",
        "    def add_tags_proba_dist(self, tag_type: str, tags: List[Label]):\n",
        "        self.tags_proba_dist[tag_type] = tags\n",
        "\n",
        "    def get_tags_proba_dist(self, tag_type: str) -> List[Label]:\n",
        "        if tag_type in self.tags_proba_dist:\n",
        "            return self.tags_proba_dist[tag_type]\n",
        "        return []\n",
        "\n",
        "    def get_head(self):\n",
        "        return self.sentence.get_token(self.head_id)\n",
        "\n",
        "    @property\n",
        "    def start_position(self) -> int:\n",
        "        return self.start_pos\n",
        "\n",
        "    @property\n",
        "    def end_position(self) -> int:\n",
        "        return self.end_pos\n",
        "\n",
        "    @property\n",
        "    def embedding(self):\n",
        "        return self.get_embedding()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "    def add_label(self, typename: str, value: str, score: float = 1.0):\n",
        "        \"\"\"\n",
        "        The Token is a special _PartOfSentence in that it may be initialized without a Sentence.\n",
        "        Therefore, labels get added only to the Sentence if it exists\n",
        "        \"\"\"\n",
        "        if self.sentence:\n",
        "            super().add_label(typename=typename, value=value, score=score)\n",
        "        else:\n",
        "            DataPoint.add_label(self, typename=typename, value=value, score=score)\n",
        "\n",
        "    def set_label(self, typename: str, value: str, score: float = 1.0):\n",
        "        \"\"\"\n",
        "        The Token is a special _PartOfSentence in that it may be initialized without a Sentence.\n",
        "        Therefore, labels get set only to the Sentence if it exists\n",
        "        \"\"\"\n",
        "        if self.sentence:\n",
        "            super().set_label(typename=typename, value=value, score=score)\n",
        "        else:\n",
        "            DataPoint.set_label(self, typename=typename, value=value, score=score)\n",
        "\n",
        "\n",
        "class Span(_PartOfSentence):\n",
        "    \"\"\"\n",
        "    This class represents one textual span consisting of Tokens. It may be used for the instance that the \n",
        "    tokens form in a nested nature, meaning the tokens combined together forms a long phrase.\n",
        "\n",
        "    :param tokens: List of tokens in the span\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tokens: List[Token]):\n",
        "        super().__init__(tokens[0].sentence)\n",
        "        self.tokens = tokens\n",
        "        super()._init_labels()\n",
        "\n",
        "    @property\n",
        "    def start_position(self) -> int:\n",
        "        return self.tokens[0].start_position\n",
        "\n",
        "    @property\n",
        "    def end_position(self) -> int:\n",
        "        return self.tokens[-1].end_position\n",
        "\n",
        "    @property\n",
        "    def text(self) -> str:\n",
        "        return \" \".join([t.text for t in self.tokens])\n",
        "\n",
        "    @property\n",
        "    def unlabeled_identifier(self) -> str:\n",
        "        return f'Span[{self.tokens[0].idx -1}:{self.tokens[-1].idx}]: \"{self.text}\"'\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Token:\n",
        "        return self.tokens[idx]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.tokens)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.tokens)\n",
        "\n",
        "    @property\n",
        "    def embedding(self):\n",
        "        pass\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "class LockedDropout(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of locked (or variational) dropout. \n",
        "    Randomly drops out entire parameters in embedding space.\n",
        "\n",
        "    :param dropout_rate: represent the fraction of the input unit to be dropped. It will be from 0 to 1.\n",
        "    :param batch_first: represent if the drop will perform in an ascending manner\n",
        "    :param inplace: \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.5, batch_first=True, inplace=False):\n",
        "        super(LockedDropout, self).__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.batch_first = batch_first\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training or not self.dropout_rate:\n",
        "            return x\n",
        "\n",
        "        if not self.batch_first:\n",
        "            m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - self.dropout_rate)\n",
        "        else:\n",
        "            m = x.data.new(x.size(0), 1, x.size(2)).bernoulli_(1 - self.dropout_rate)\n",
        "\n",
        "        mask = torch.autograd.Variable(m, requires_grad=False) / (1 - self.dropout_rate)\n",
        "        mask = mask.expand_as(x)\n",
        "        return mask * x\n",
        "\n",
        "    def extra_repr(self):\n",
        "        inplace_str = \", inplace\" if self.inplace else \"\"\n",
        "        return \"p={}{}\".format(self.dropout_rate, inplace_str)\n",
        "\n",
        "\n",
        "class WordDropout(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of word dropout. Randomly drops out entire words \n",
        "    (or characters) in embedding space.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout_rate=0.05, inplace=False):\n",
        "        super(WordDropout, self).__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.inplace = inplace\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training or not self.dropout_rate:\n",
        "            return x\n",
        "\n",
        "        m = x.data.new(x.size(0), x.size(1), 1).bernoulli_(1 - self.dropout_rate)\n",
        "\n",
        "        mask = torch.autograd.Variable(m, requires_grad=False)\n",
        "        return mask * x\n",
        "\n",
        "    def extra_repr(self):\n",
        "        inplace_str = \", inplace\" if self.inplace else \"\"\n",
        "        return \"p={}{}\".format(self.dropout_rate, inplace_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zAjoyg7Vg99a"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "import torch\n",
        "import torch.nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from tqdm import tqdm\n",
        "\n",
        "import flair.nn\n",
        "from flair.data import Dictionary, Label, Sentence, Span\n",
        "from flair.datasets import DataLoader, FlairDatapointDataset\n",
        "from flair.embeddings import StackedEmbeddings, TokenEmbeddings\n",
        "from flair.file_utils import cached_path\n",
        "from flair.training_utils import store_embeddings\n",
        "\n",
        "log = logging.getLogger(\"flair\")\n",
        "\n",
        "\n",
        "class Bi_LSTM_CRF(flair.nn.Classifier[Sentence]):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embeddings: TokenEmbeddings,\n",
        "        tag_dictionary: Dictionary,\n",
        "        tag_type: str,\n",
        "        rnn: Optional[torch.nn.RNN] = None,\n",
        "        tag_format: str = \"BIOES\",\n",
        "        hidden_size: int = 256,\n",
        "        rnn_layers: int = 1,\n",
        "        bidirectional: bool = True,\n",
        "        use_crf: bool = True,\n",
        "        ave_embeddings: bool = True,\n",
        "        dropout: float = 0.0,\n",
        "        word_dropout: float = 0.05,\n",
        "        locked_dropout: float = 0.5,\n",
        "        loss_weights: Dict[str, float] = None,\n",
        "        init_from_state_dict: bool = False,\n",
        "        allow_unk_predictions: bool = False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        BiLSTM Span CRF class for predicting labels for single tokens. Can be parameterized by several attributes.\n",
        "        Span prediction is utilized if there are nested entities such as Address and Organization. Since the researchers\n",
        "        observed that the token are have different length for a given dataset, we made the Span useful by incorporating it \n",
        "        only if the data needs it. \n",
        "\n",
        "        :param embeddings: Embeddings to use during training and prediction\n",
        "        :param tag_dictionary: Dictionary containing all tags from corpus which can be predicted\n",
        "        :param tag_type: type of tag which is going to be predicted in case a corpus has multiple annotations\n",
        "        :param rnn: (Optional) Takes a torch.nn.Module as parameter by which you can pass a shared RNN between\n",
        "            different tasks.\n",
        "        :param hidden_size: Hidden size of RNN layer\n",
        "        :param rnn_layers: number of RNN layers\n",
        "        :param bidirectional: If True, RNN becomes bidirectional\n",
        "        :param use_crf: If True, use a Conditional Random Field for prediction, else linear map to tag space.\n",
        "        :param ave_embeddings: If True, add a linear layer on top of embeddings, if you want to imitate\n",
        "            fine tune non-trainable embeddings.\n",
        "        :param dropout: If > 0, then use dropout.\n",
        "        :param word_dropout: If > 0, then use word dropout.\n",
        "        :param locked_dropout: If > 0, then use locked dropout.\n",
        "        :param loss_weights: Dictionary of weights for labels for the loss function\n",
        "            (if any label's weight is unspecified it will default to 1.0)\n",
        "        :param init_from_state_dict: Indicator whether we are loading a model from state dict\n",
        "            since we need to transform previous models' weights into CRF instance weights\n",
        "        \"\"\"\n",
        "        super(Bi_LSTM_CRF, self).__init__()\n",
        "\n",
        "        # ----- Create the internal tag dictionary -----\n",
        "        self.tag_type = tag_type\n",
        "        self.tag_format = tag_format.upper()\n",
        "        if init_from_state_dict:\n",
        "            self.label_dictionary = tag_dictionary\n",
        "        else:\n",
        "            # span-labels need special encoding (BIO or BIOES)\n",
        "            if tag_dictionary.span_labels:\n",
        "                # the big question is whether the label dictionary should contain an UNK or not\n",
        "                # without UNK, we cannot evaluate on data that contains labels not seen in test\n",
        "                # with UNK, the model learns less well if there are no UNK examples\n",
        "                self.label_dictionary = Dictionary(add_unk=allow_unk_predictions)\n",
        "                assert self.tag_format in [\"BIOES\", \"BIO\"]\n",
        "                for label in tag_dictionary.get_items():\n",
        "                    if label == \"<unk>\":\n",
        "                        continue\n",
        "                    self.label_dictionary.add_item(\"O\")\n",
        "                    if self.tag_format == \"BIOES\":\n",
        "                        self.label_dictionary.add_item(\"S-\" + label)\n",
        "                        self.label_dictionary.add_item(\"B-\" + label)\n",
        "                        self.label_dictionary.add_item(\"E-\" + label)\n",
        "                        self.label_dictionary.add_item(\"I-\" + label)\n",
        "                    if self.tag_format == \"BIO\":\n",
        "                        self.label_dictionary.add_item(\"B-\" + label)\n",
        "                        self.label_dictionary.add_item(\"I-\" + label)\n",
        "            else:\n",
        "                self.label_dictionary = tag_dictionary\n",
        "\n",
        "        # is this a span prediction problem?\n",
        "        self.predict_spans = self._determine_if_span_prediction_problem(self.label_dictionary)\n",
        "\n",
        "        self.tagset_size = len(self.label_dictionary)\n",
        "        log.info(f\"SequenceTagger predicts: {self.label_dictionary}\")\n",
        "\n",
        "        # ----- Embeddings -----\n",
        "        # We set the first initial embeddings gathered from Flair \n",
        "        # Stacked and concatenated then ave. using Linear\n",
        "        self.embeddings = embeddings\n",
        "        embedding_dim: int = embeddings.embedding_length\n",
        "\n",
        "        # ----- Initial loss weights parameters -----\n",
        "        # This is for reiteration process of training.\n",
        "        # Initially we don't have any loss weights, but as we proceed to training, \n",
        "        # we get loss computations from the evaluation stage.\n",
        "        self.weight_dict = loss_weights\n",
        "        self.loss_weights = self._init_loss_weights(loss_weights) if loss_weights else None\n",
        "\n",
        "        # ----- RNN specific parameters -----\n",
        "        # These parameters are for setting up the self.RNN \n",
        "        self.hidden_size = hidden_size if not rnn else rnn.hidden_size\n",
        "        self.rnn_layers = rnn_layers if not rnn else rnn.num_layers\n",
        "        self.bidirectional = bidirectional if not rnn else rnn.bidirectional\n",
        "\n",
        "        # ----- Conditional Random Field parameters -----\n",
        "        self.use_crf = use_crf\n",
        "        # Previously trained models have been trained without an explicit CRF, thus it is required to check\n",
        "        # whether we are loading a model from state dict in order to skip or add START and STOP token\n",
        "        if use_crf and not init_from_state_dict and not self.label_dictionary.start_stop_tags_are_set():\n",
        "            self.label_dictionary.set_start_stop_tags()\n",
        "            self.tagset_size += 2\n",
        "\n",
        "        # ----- Dropout parameters -----\n",
        "        # dropouts\n",
        "        self.use_dropout: float = dropout\n",
        "        self.use_word_dropout: float = word_dropout\n",
        "        self.use_locked_dropout: float = locked_dropout\n",
        "\n",
        "        if dropout > 0.0:\n",
        "            self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        if word_dropout > 0.0:\n",
        "            self.word_dropout = flair.nn.WordDropout(word_dropout)\n",
        "\n",
        "        if locked_dropout > 0.0:\n",
        "            self.locked_dropout = flair.nn.LockedDropout(locked_dropout)\n",
        "\n",
        "        # ----- Model layers -----\n",
        "        # Initialize Embedding Linear Dim for the purpose of ave them\n",
        "        self.ave_embeddings = ave_embeddings\n",
        "        if self.ave_embeddings:\n",
        "            self.embedding2nn = torch.nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "        # ----- RNN layer -----\n",
        "        # If shared RNN provided, else create one for model\n",
        "        self.rnn: torch.nn.RNN = (\n",
        "            rnn\n",
        "            if rnn\n",
        "            else LSTM(\n",
        "                rnn_layers,\n",
        "                hidden_size,\n",
        "                bidirectional,\n",
        "                rnn_input_dim=embedding_dim,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "        hidden_output_dim = self.rnn.hidden_size * num_directions\n",
        "\n",
        "     \n",
        "        # final linear map to tag space\n",
        "        self.linear = torch.nn.Linear(hidden_output_dim, len(self.label_dictionary))\n",
        "\n",
        "\n",
        "        # the loss function is Viterbi if using CRF, else regular Cross Entropy Loss\n",
        "        self.loss_function = (\n",
        "            ViterbiLoss(self.label_dictionary)\n",
        "        )\n",
        "\n",
        "        # if using CRF, we also require a CRF and a Viterbi decoder\n",
        "        if use_crf:\n",
        "            self.crf = CRF(self.label_dictionary, self.tagset_size, init_from_state_dict)\n",
        "            self.viterbi_decoder = ViterbiDecoder(self.label_dictionary)\n",
        "\n",
        "        self.to(flair.device)\n",
        "\n",
        "    @property\n",
        "    def label_type(self):\n",
        "        return self.tag_type\n",
        "\n",
        "    def _init_loss_weights(self, loss_weights: Dict[str, float]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Intializes the loss weights based on given dictionary:\n",
        "        :param loss_weights: dictionary - contains loss weights\n",
        "        \"\"\"\n",
        "        n_classes = len(self.label_dictionary)\n",
        "        weight_list = [1.0 for _ in range(n_classes)]\n",
        "        for i, tag in enumerate(self.label_dictionary.get_items()):\n",
        "            if tag in loss_weights.keys():\n",
        "                weight_list[i] = loss_weights[tag]\n",
        "\n",
        "        return torch.tensor(weight_list).to(flair.device)\n",
        "\n",
        "    def forward_loss(self, sentences: Union[List[Sentence], Sentence]) -> Tuple[torch.Tensor, int]:\n",
        "        \"\"\"\n",
        "        Calculates the loss of the forward propagation of the model\n",
        "        :param sentences: either a listof sentence or just a sentence\n",
        "        \"\"\"\n",
        "        # if there are no sentences, there is no loss\n",
        "        if len(sentences) == 0:\n",
        "            return torch.tensor(0.0, dtype=torch.float, device=flair.device, requires_grad=True), 0\n",
        "\n",
        "        # forward pass to get scores\n",
        "        scores, gold_labels = self.forward(sentences)  # type: ignore\n",
        "\n",
        "        # calculate loss given scores and labels\n",
        "        return self._calculate_loss(scores, gold_labels)\n",
        "\n",
        "    def forward(self, sentences: Union[List[Sentence], Sentence]):\n",
        "        \"\"\"\n",
        "        Forward propagation through network. Returns gold labels of batch in addition.\n",
        "        :param sentences: Batch of current sentences\n",
        "        \"\"\"\n",
        "        if not isinstance(sentences, list):\n",
        "            sentences = [sentences]\n",
        "        self.embeddings.embed(sentences)\n",
        "\n",
        "        # make a zero-padded tensor for the whole sentence\n",
        "        lengths, sentence_tensor = self._make_padded_tensor_for_batch(sentences)\n",
        "\n",
        "        # sort tensor in decreasing order based on lengths of sentences in batch\n",
        "        sorted_lengths, length_indices = lengths.sort(dim=0, descending=True)\n",
        "        sentences = [sentences[i] for i in length_indices]\n",
        "        sentence_tensor = sentence_tensor[length_indices]\n",
        "\n",
        "        # ----- Forward Propagation -----\n",
        "        # we get the dropout we initialize for th regularization\n",
        "        # of our inputs\n",
        "        if self.use_dropout:\n",
        "            sentence_tensor = self.dropout(sentence_tensor)\n",
        "        if self.use_word_dropout:\n",
        "            sentence_tensor = self.word_dropout(sentence_tensor)\n",
        "        if self.use_locked_dropout:\n",
        "            sentence_tensor = self.locked_dropout(sentence_tensor)\n",
        "\n",
        "        # Average the embeddings using Linear Transform\n",
        "        if self.ave_embeddings:\n",
        "            sentence_tensor = self.embedding2nn(sentence_tensor)\n",
        "\n",
        "        # This packs our Sentence tensor form, the process for weighting\n",
        "        # our LSTM model\n",
        "        sentence_tensor, output_lengths = self.rnn(sentence_tensor, sorted_lengths)\n",
        "\n",
        "        # Regularize our computed sentence tensor form the LSTM model\n",
        "        if self.use_dropout:\n",
        "            sentence_tensor = self.dropout(sentence_tensor)\n",
        "        if self.use_locked_dropout:\n",
        "            sentence_tensor = self.locked_dropout(sentence_tensor)\n",
        "\n",
        "        # linear map to tag space\n",
        "        features = self.linear(sentence_tensor)\n",
        "\n",
        "        # Depending on whether we are using CRF or a linear layer, scores is either:\n",
        "        # -- A tensor of shape (batch size, sequence length, tagset size, tagset size) for CRF\n",
        "        # -- A tensor of shape (aggregated sequence length for all sentences in batch, tagset size) for linear layer\n",
        "        if self.use_crf:\n",
        "            features = self.crf(features)\n",
        "            scores = (features, sorted_lengths, self.crf.transitions)\n",
        "        else:\n",
        "            scores = self._get_scores_from_features(features, sorted_lengths)\n",
        "\n",
        "        # get the gold labels\n",
        "        gold_labels = self._get_gold_labels(sentences)\n",
        "\n",
        "        return scores, gold_labels\n",
        "\n",
        "    def _calculate_loss(self, scores, labels) -> Tuple[torch.Tensor, int]:\n",
        "\n",
        "        if not any(labels):\n",
        "            return torch.tensor(0.0, requires_grad=True, device=flair.device), 1\n",
        "\n",
        "        labels = torch.tensor(\n",
        "            [\n",
        "                self.label_dictionary.get_idx_for_item(label[0])\n",
        "                if len(label) > 0\n",
        "                else self.label_dictionary.get_idx_for_item(\"O\")\n",
        "                for label in labels\n",
        "            ],\n",
        "            dtype=torch.long,\n",
        "            device=flair.device,\n",
        "        )\n",
        "\n",
        "        return self.loss_function(scores, labels), len(labels)\n",
        "\n",
        "    def _make_padded_tensor_for_batch(self, sentences: List[Sentence]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        makes zero padded tensors in the shape of the max longest sentence and the embedding_length to match \n",
        "        the shape of the embedding in feeding to our LSTM model.\n",
        "        :param sentences: Batch of current sentences\n",
        "        \"\"\"\n",
        "        names = self.embeddings.get_names()\n",
        "        tok_lengths: List[int] = [len(sentence.tokens) for sentence in sentences]\n",
        "        longest_token_sequence_in_batch: int = max(tok_lengths)\n",
        "        zero_tensor = torch.zeros(\n",
        "            self.embeddings.embedding_length * longest_token_sequence_in_batch,\n",
        "            dtype=torch.float,\n",
        "            device=flair.device,\n",
        "        )\n",
        "        all_embs = list()\n",
        "        for sentence in sentences:\n",
        "            all_embs += [emb for token in sentence for emb in token.get_each_embedding(names)]\n",
        "            nb_padding_tokens = longest_token_sequence_in_batch - len(sentence)\n",
        "\n",
        "            if nb_padding_tokens > 0:\n",
        "                t = zero_tensor[: self.embeddings.embedding_length * nb_padding_tokens]\n",
        "                all_embs.append(t)\n",
        "\n",
        "        sentence_tensor = torch.cat(all_embs).view(\n",
        "            [\n",
        "                len(sentences),\n",
        "                longest_token_sequence_in_batch,\n",
        "                self.embeddings.embedding_length,\n",
        "            ]\n",
        "        )\n",
        "        return torch.tensor(tok_lengths, dtype=torch.long), sentence_tensor\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_scores_from_features(features: torch.Tensor, lengths: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Trims current batch tensor in shape (batch size, sequence length, tagset size) in such a way that all\n",
        "        pads are going to be removed.\n",
        "        :param features: torch.tensor containing all features from forward propagation\n",
        "        :param lengths: length from each sentence in batch in order to trim padding tokens\n",
        "        \"\"\"\n",
        "        features_formatted = []\n",
        "        for feat, lens in zip(features, lengths):\n",
        "            features_formatted.append(feat[:lens])\n",
        "        scores = torch.cat(features_formatted)\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def _get_gold_labels(self, sentences: Union[List[Sentence], Sentence]):\n",
        "        \"\"\"\n",
        "        Extracts gold labels from each sentence.\n",
        "        :param sentences: List of sentences in batch\n",
        "        \"\"\"\n",
        "        # spans need to be encoded as token-level predictions\n",
        "        if self.predict_spans:\n",
        "            all_sentence_labels = []\n",
        "            for sentence in sentences:\n",
        "                sentence_labels = [\"O\"] * len(sentence)\n",
        "                for label in sentence.get_labels(self.label_type):\n",
        "                    span: Span = label.data_point\n",
        "                    if self.tag_format == \"BIOES\":\n",
        "                        if len(span) == 1:\n",
        "                            sentence_labels[span[0].idx - 1] = \"S-\" + label.value\n",
        "                        else:\n",
        "                            sentence_labels[span[0].idx - 1] = \"B-\" + label.value\n",
        "                            sentence_labels[span[-1].idx - 1] = \"E-\" + label.value\n",
        "                            for i in range(span[0].idx, span[-1].idx - 1):\n",
        "                                sentence_labels[i] = \"I-\" + label.value\n",
        "                    else:\n",
        "                        sentence_labels[span[0].idx - 1] = \"B-\" + label.value\n",
        "                        for i in range(span[0].idx, span[-1].idx):\n",
        "                            sentence_labels[i] = \"I-\" + label.value\n",
        "                all_sentence_labels.extend(sentence_labels)\n",
        "            labels = [[label] for label in all_sentence_labels]\n",
        "\n",
        "        # all others are regular labels for each token\n",
        "        else:\n",
        "            labels = [[token.get_label(self.label_type, \"O\").value] for sentence in sentences for token in sentence]\n",
        "\n",
        "        return labels\n",
        "\n",
        "    def predict(\n",
        "        self,\n",
        "        sentences: Union[List[Sentence], Sentence],\n",
        "        mini_batch_size: int = 32,\n",
        "        return_probabilities_for_all_classes: bool = False,\n",
        "        verbose: bool = False,\n",
        "        label_name: Optional[str] = None,\n",
        "        return_loss=False,\n",
        "        embedding_storage_mode=\"none\",\n",
        "        force_token_predictions: bool = False,\n",
        "    ):  # type: ignore\n",
        "        \"\"\"\n",
        "        Predicts labels for current batch with CRF.\n",
        "        :param sentences: List of sentences in batch\n",
        "        :param mini_batch_size: batch size for test data\n",
        "        :param return_probabilities_for_all_classes: Whether to return probabilites for all classes\n",
        "        :param verbose: whether to use progress bar\n",
        "        :param label_name: which label to predict\n",
        "        :param return_loss: whether to return loss value\n",
        "        :param embedding_storage_mode: determines where to store embeddings - can be \"gpu\", \"cpu\" or None.\n",
        "        \"\"\"\n",
        "        if label_name is None:\n",
        "            label_name = self.tag_type\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if not sentences:\n",
        "                return sentences\n",
        "\n",
        "            # make sure its a list\n",
        "            if not isinstance(sentences, list) and not isinstance(sentences, flair.data.Dataset):\n",
        "                sentences = [sentences]\n",
        "\n",
        "            # filter empty sentences\n",
        "            sentences = [sentence for sentence in sentences if len(sentence) > 0]\n",
        "\n",
        "            # reverse sort all sequences by their length\n",
        "            reordered_sentences = sorted(sentences, key=lambda s: len(s), reverse=True)\n",
        "\n",
        "            if len(reordered_sentences) == 0:\n",
        "                return sentences\n",
        "\n",
        "            dataloader = DataLoader(\n",
        "                dataset=FlairDatapointDataset(reordered_sentences),\n",
        "                batch_size=mini_batch_size,\n",
        "            )\n",
        "            # progress bar for verbosity\n",
        "            if verbose:\n",
        "                dataloader = tqdm(dataloader, desc=\"Batch inference\")\n",
        "\n",
        "            overall_loss = torch.zeros(1, device=flair.device)\n",
        "            batch_no = 0\n",
        "            label_count = 0\n",
        "            for batch in dataloader:\n",
        "\n",
        "                batch_no += 1\n",
        "\n",
        "                # stop if all sentences are empty\n",
        "                if not batch:\n",
        "                    continue\n",
        "\n",
        "                # get features from forward propagation\n",
        "                features, gold_labels = self.forward(batch)\n",
        "\n",
        "                # remove previously predicted labels of this type\n",
        "                for sentence in batch:\n",
        "                    sentence.remove_labels(label_name)\n",
        "\n",
        "                # if return_loss, get loss value\n",
        "                if return_loss:\n",
        "                    loss = self._calculate_loss(features, gold_labels)\n",
        "                    overall_loss += loss[0]\n",
        "                    label_count += loss[1]\n",
        "\n",
        "                # Sort batch in same way as forward propagation\n",
        "                lengths = torch.LongTensor([len(sentence) for sentence in batch])\n",
        "                _, sort_indices = lengths.sort(dim=0, descending=True)\n",
        "                batch = [batch[i] for i in sort_indices]\n",
        "\n",
        "                # make predictions\n",
        "                if self.use_crf:\n",
        "                    predictions, all_tags = self.viterbi_decoder.decode(\n",
        "                        features, return_probabilities_for_all_classes, batch\n",
        "                    )\n",
        "                else:\n",
        "                    predictions, all_tags = self._standard_inference(\n",
        "                        features, batch, return_probabilities_for_all_classes\n",
        "                    )\n",
        "\n",
        "                # add predictions to Sentence\n",
        "                for sentence, sentence_predictions in zip(batch, predictions):\n",
        "\n",
        "                    # BIOES-labels need to be converted to spans\n",
        "                    if self.predict_spans and not force_token_predictions:\n",
        "                        sentence_tags = [label[0] for label in sentence_predictions]\n",
        "                        sentence_scores = [label[1] for label in sentence_predictions]\n",
        "                        predicted_spans = get_spans_from_bio(sentence_tags, sentence_scores)\n",
        "                        for predicted_span in predicted_spans:\n",
        "                            span: Span = sentence[predicted_span[0][0] : predicted_span[0][-1] + 1]\n",
        "                            span.add_label(label_name, value=predicted_span[2], score=predicted_span[1])\n",
        "\n",
        "                    # token-labels can be added directly (\"O\" and legacy \"_\" predictions are skipped)\n",
        "                    else:\n",
        "                        for token, label in zip(sentence.tokens, sentence_predictions):\n",
        "                            if label[0] in [\"O\", \"_\"]:\n",
        "                                continue\n",
        "                            token.add_label(typename=label_name, value=label[0], score=label[1])\n",
        "\n",
        "                # all_tags will be empty if all_tag_prob is set to False, so the for loop will be avoided\n",
        "                for (sentence, sent_all_tags) in zip(batch, all_tags):\n",
        "                    for (token, token_all_tags) in zip(sentence.tokens, sent_all_tags):\n",
        "                        token.add_tags_proba_dist(label_name, token_all_tags)\n",
        "\n",
        "                store_embeddings(sentences, storage_mode=embedding_storage_mode)\n",
        "\n",
        "            if return_loss:\n",
        "                return overall_loss, label_count\n",
        "\n",
        "    def _standard_inference(self, features: torch.Tensor, batch: List[Sentence], probabilities_for_all_classes: bool):\n",
        "        \"\"\"\n",
        "        Softmax over emission scores from forward propagation.\n",
        "        :param features: sentence tensor from forward propagation\n",
        "        :param batch: list of sentence\n",
        "        :param probabilities_for_all_classes: whether to return score for each tag in tag dictionary\n",
        "        \"\"\"\n",
        "        softmax_batch = F.softmax(features, dim=1).cpu()\n",
        "        scores_batch, prediction_batch = torch.max(softmax_batch, dim=1)\n",
        "        predictions = []\n",
        "        all_tags = []\n",
        "\n",
        "        for sentence in batch:\n",
        "            scores = scores_batch[: len(sentence)]\n",
        "            predictions_for_sentence = prediction_batch[: len(sentence)]\n",
        "            predictions.append(\n",
        "                [\n",
        "                    (self.label_dictionary.get_item_for_index(prediction), score.item())\n",
        "                    for token, score, prediction in zip(sentence, scores, predictions_for_sentence)\n",
        "                ]\n",
        "            )\n",
        "            scores_batch = scores_batch[len(sentence) :]\n",
        "            prediction_batch = prediction_batch[len(sentence) :]\n",
        "\n",
        "        if probabilities_for_all_classes:\n",
        "            lengths = [len(sentence) for sentence in batch]\n",
        "            all_tags = self._all_scores_for_token(batch, softmax_batch, lengths)\n",
        "\n",
        "        return predictions, all_tags\n",
        "\n",
        "    def _all_scores_for_token(self, sentences: List[Sentence], scores: torch.Tensor, lengths: List[int]):\n",
        "        \"\"\"\n",
        "        Returns all scores for each tag in tag dictionary.\n",
        "        :param scores: Scores for current sentence.\n",
        "        \"\"\"\n",
        "        scores = scores.numpy()\n",
        "        tokens = [token for sentence in sentences for token in sentence]\n",
        "        prob_all_tags = [\n",
        "            [\n",
        "                Label(token, self.label_dictionary.get_item_for_index(score_id), score)\n",
        "                for score_id, score in enumerate(score_dist)\n",
        "            ]\n",
        "            for score_dist, token in zip(scores, tokens)\n",
        "        ]\n",
        "\n",
        "        prob_tags_per_sentence = []\n",
        "        previous = 0\n",
        "        for length in lengths:\n",
        "            prob_tags_per_sentence.append(prob_all_tags[previous : previous + length])\n",
        "            previous = length\n",
        "        return prob_tags_per_sentence\n",
        "\n",
        "    def _get_state_dict(self):\n",
        "        \"\"\"Returns the state dictionary for this model.\"\"\"\n",
        "        model_state = {\n",
        "            **super()._get_state_dict(),\n",
        "            \"embeddings\": self.embeddings,\n",
        "            \"hidden_size\": self.hidden_size,\n",
        "            \"tag_dictionary\": self.label_dictionary,\n",
        "            \"tag_format\": self.tag_format,\n",
        "            \"tag_type\": self.tag_type,\n",
        "            \"use_crf\": self.use_crf,\n",
        "            \"rnn_layers\": self.rnn_layers,\n",
        "            \"use_dropout\": self.use_dropout,\n",
        "            \"use_word_dropout\": self.use_word_dropout,\n",
        "            \"use_locked_dropout\": self.use_locked_dropout,\n",
        "            \"ave_embeddings\": self.ave_embeddings,\n",
        "            \"weight_dict\": self.weight_dict,\n",
        "        }\n",
        "\n",
        "        return model_state\n",
        "\n",
        "    @classmethod\n",
        "    def _init_model_with_state_dict(cls, state, **kwargs):\n",
        "\n",
        "        if state[\"use_crf\"]:\n",
        "            if \"transitions\" in state[\"state_dict\"]:\n",
        "                state[\"state_dict\"][\"crf.transitions\"] = state[\"state_dict\"][\"transitions\"]\n",
        "                del state[\"state_dict\"][\"transitions\"]\n",
        "\n",
        "        return super()._init_model_with_state_dict(\n",
        "            state,\n",
        "            embeddings=state.get(\"embeddings\"),\n",
        "            tag_dictionary=state.get(\"tag_dictionary\"),\n",
        "            tag_format=state.get(\"tag_format\", \"BIOES\"),\n",
        "            tag_type=state.get(\"tag_type\"),\n",
        "            use_crf=state.get(\"use_crf\"),\n",
        "            rnn_layers=state.get(\"rnn_layers\"),\n",
        "            hidden_size=state.get(\"hidden_size\"),\n",
        "            dropout=state.get(\"use_dropout\", 0.0),\n",
        "            word_dropout=state.get(\"use_word_dropout\", 0.0),\n",
        "            locked_dropout=state.get(\"use_locked_dropout\", 0.0),\n",
        "            ave_embeddings=state.get(\"ave_embeddings\", True),\n",
        "            loss_weights=state.get(\"weight_dict\"),\n",
        "            init_from_state_dict=True,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _filter_empty_sentences(sentences: List[Sentence]) -> List[Sentence]:\n",
        "        filtered_sentences = [sentence for sentence in sentences if sentence.tokens]\n",
        "        if len(sentences) != len(filtered_sentences):\n",
        "            log.warning(f\"Ignore {len(sentences) - len(filtered_sentences)} sentence(s) with no tokens.\")\n",
        "        return filtered_sentences\n",
        "\n",
        "    def _determine_if_span_prediction_problem(self, dictionary: Dictionary) -> bool:\n",
        "        for item in dictionary.get_items():\n",
        "            if item.startswith(\"B-\") or item.startswith(\"S-\") or item.startswith(\"I-\"):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def _print_predictions(self, batch, gold_label_type):\n",
        "\n",
        "        lines = []\n",
        "        if self.predict_spans:\n",
        "            for datapoint in batch:\n",
        "                # all labels default to \"O\"\n",
        "                for token in datapoint:\n",
        "                    token.set_label(\"gold_bio\", \"O\")\n",
        "                    token.set_label(\"predicted_bio\", \"O\")\n",
        "\n",
        "                # set gold token-level\n",
        "                for gold_label in datapoint.get_labels(gold_label_type):\n",
        "                    gold_span: Span = gold_label.data_point\n",
        "                    prefix = \"B-\"\n",
        "                    for token in gold_span:\n",
        "                        token.set_label(\"gold_bio\", prefix + gold_label.value)\n",
        "                        prefix = \"I-\"\n",
        "\n",
        "                # set predicted token-level\n",
        "                for predicted_label in datapoint.get_labels(\"predicted\"):\n",
        "                    predicted_span: Span = predicted_label.data_point\n",
        "                    prefix = \"B-\"\n",
        "                    for token in predicted_span:\n",
        "                        token.set_label(\"predicted_bio\", prefix + predicted_label.value)\n",
        "                        prefix = \"I-\"\n",
        "\n",
        "                # now print labels in CoNLL format\n",
        "                for token in datapoint:\n",
        "                    eval_line = (\n",
        "                        f\"{token.text} \"\n",
        "                        f\"{token.get_label('gold_bio').value} \"\n",
        "                        f\"{token.get_label('predicted_bio').value}\\n\"\n",
        "                    )\n",
        "                    lines.append(eval_line)\n",
        "                lines.append(\"\\n\")\n",
        "\n",
        "        else:\n",
        "            for datapoint in batch:\n",
        "                # print labels in CoNLL format\n",
        "                for token in datapoint:\n",
        "                    eval_line = (\n",
        "                        f\"{token.text} \"\n",
        "                        f\"{token.get_label(gold_label_type).value} \"\n",
        "                        f\"{token.get_label('predicted').value}\\n\"\n",
        "                    )\n",
        "                    lines.append(eval_line)\n",
        "                lines.append(\"\\n\")\n",
        "        return lines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437,
          "referenced_widgets": [
            "1d7ad7fa0e5544fcb5bfccd4f2416c62",
            "c747ab66c2b443719f3c35a1a0651018",
            "780070dcb8b44ad687833b42cf45fa0f",
            "ef5b1b6f66344519989a43cd60440ae7",
            "efa13989e75542dd952d45daa3e61e34",
            "3952eeec853c4eb1b60a6f21c5c8e899",
            "0064395e0bf5463b9d7d60efbaba847b",
            "5522ead4b6d34ebd8fee030981aa6199",
            "1ad11bd99f2b4769bd09096f7a9f6540",
            "363425048fc04711a8a9becdd25b4b56",
            "3c61fc754bc44e9296d39f21ac524a11",
            "04204f841327487ea5fc93b000af4406",
            "dd583e5ecb9c4c68aec0a6daf4f59c2e",
            "2d6f63ca55654fac83de65c9421c52e1",
            "a3394f1ab4f04848afb93dc0a67f126c",
            "fddde349fc6c44beb65aa7cd7f9681b8",
            "fc52c958796a4ba4b000a74522696ddb",
            "3c3ed9b070e946b5a17d3b5fbe57df3f",
            "a772497dcf4e477e8b81c1cd64f43e25",
            "9e3be13e2cbe4370bf754910a078bd74",
            "8669047aeffa4f5f84b8cba7696910d8",
            "7a61a15189a3418fb42117eaaf98c104",
            "3531c31ab3514cb4abc743b59e5b2a5d",
            "13a9103041ff41779e9c9eb094737faa",
            "6eda3350421b4bdaafa4cd41d26679df",
            "3cf712ed0ff1461b816b85e5adc0eca7",
            "c415eeb4eb1443adaae056d85767508b",
            "ea81ef14f82d4523ad27e5a36385bb5a",
            "166a03674909478dace114b108b0328b",
            "8eeeb57619534e1c9b924511c4439191",
            "87301259f21b47c69a8a9847cbf68b3c",
            "9412e47775444a828762681bf92ea6ae",
            "1f82631f851049fe9d0e1d2c405a4178",
            "19f8c8a957a04f3b9e6a8761c4c2dbd5",
            "9ac5e0cea9414703bcc8961206b0b23b",
            "0785c5838dfd4fc4b2e67c6771d0ef75",
            "ce42975c12054a9b8454d92b02036892",
            "f324a6bd93814355984ac610902c684f",
            "521decf7ef104397bf24271871e20076",
            "35c11dd7d2594d55b7577a93a91c0560",
            "7f4659d36cb6483abfc779e159df8370",
            "b95f5ce153ea427b91a6d5a843bc73c9",
            "b59dfae24cdc401796d19c4671693652",
            "68d47641f07d44dcb9d5e3ac6bf89661",
            "77a3fd4346e04db8b55d7eb54a6c52cf",
            "6ab78ec85ae14d44b17eb3095bb93b8d",
            "e5217e570a8f499cbe7f51149924488d",
            "5d45c582078b4c658adbecf8cf36cf26",
            "70e2ce7d826b4cc2aac3f2e603cba618",
            "04745b1bbf8442238f95b92a55c78961",
            "b1cf2cc291c84e7d9c3857becfd3dec2",
            "382ef5bd06f94f3ca290e0e65d4b527b",
            "bb02eeaf646b41fe856a6ec7a62dd289",
            "f8ec8700ebd242a9bf703eeb7690e78e",
            "02a4443c76704c11b9cfb711924f8d0d",
            "ca0650497f6944beae48e538a27b26a5",
            "292456e7e2bb48ebb0f2348a1039d42c",
            "70878c7ee8e34d44b14d9b6601f57811",
            "4b942b9a28834e74aa0adc6fcc14f2eb",
            "ed8acdcf4c114bb89f801943d493ec53",
            "fa4e2db20c3d4bcf853afbe4fa401865",
            "b78e38567a694c408e6599abf4e2d6e1",
            "4186ce2ba08b4d92865147b4c39f061e",
            "7ebdf85ea2a346d9a9e19d4a2765fe09",
            "11eed811849847a6b0226a4a09281eb4",
            "8aeb65d1a2d34de4b6158790b00cda96"
          ]
        },
        "id": "O3gyoxxmjXBL",
        "outputId": "ad1979b5-82ad-4942-af1e-addaff82063b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 07:48:59,362 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpn1mwnm_b\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:03<00:00, 6483622.32B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 07:49:03,090 copying /tmp/tmpn1mwnm_b to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2022-08-29 07:49:03,116 removing temp file /tmp/tmpn1mwnm_b\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 07:49:16,818 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpc7knnobz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:02<00:00, 6646521.63B/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 07:49:20,469 copying /tmp/tmpc7knnobz to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2022-08-29 07:49:20,502 removing temp file /tmp/tmpc7knnobz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d7ad7fa0e5544fcb5bfccd4f2416c62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04204f841327487ea5fc93b000af4406",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3531c31ab3514cb4abc743b59e5b2a5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19f8c8a957a04f3b9e6a8761c4c2dbd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77a3fd4346e04db8b55d7eb54a6c52cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca0650497f6944beae48e538a27b26a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/413M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 07:49:48,118 https://flair.informatik.hu-berlin.de/resources/characters/common_characters not found in cache, downloading to /tmp/tmpge9qbhj1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2887/2887 [00:00<00:00, 1576276.44B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 07:49:48,795 copying /tmp/tmpge9qbhj1 to cache at /root/.flair/datasets/common_characters\n",
            "2022-08-29 07:49:48,797 removing temp file /tmp/tmpge9qbhj1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from flair.embeddings import (\n",
        "    TransformerWordEmbeddings,\n",
        "    WordEmbeddings,\n",
        "    FlairEmbeddings,\n",
        "    CharacterEmbeddings,\n",
        "    DocumentRNNEmbeddings,\n",
        "    OneHotEmbeddings,\n",
        "    StackedEmbeddings\n",
        ")\n",
        "from flair.data import Sentence\n",
        "import torch\n",
        "import flair\n",
        "\n",
        "flair.device = torch.device('cuda:0') \n",
        "\n",
        "flair_forward_embedding = FlairEmbeddings(\"news-forward-fast\")\n",
        "flair_backward_embedding = FlairEmbeddings(\"news-backward-fast\")\n",
        "\n",
        "bert_embedding = TransformerWordEmbeddings(model='dslim/bert-base-NER',\n",
        "                                       fine_tune=True,\n",
        "                                       use_context=True,\n",
        "                                       )\n",
        "char_embedding = CharacterEmbeddings()\n",
        "\n",
        "embeddings = StackedEmbeddings(\n",
        "        [\n",
        "            bert_embedding,\n",
        "            flair_forward_embedding, \n",
        "            flair_backward_embedding, \n",
        "        ]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZodc3YykMlM",
        "outputId": "aee8bc6c-9152-44f9-c36f-94f6c82ca684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "2022-08-29 07:50:17,899 Reading data from /content\n",
            "2022-08-29 07:50:17,903 Train: /content/eng.train.txt\n",
            "2022-08-29 07:50:17,910 Dev: /content/eng.train50000.txt\n",
            "2022-08-29 07:50:17,912 Test: /content/eng.testb.txt\n",
            "14986\n",
            "2022-08-29 07:50:31,806 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14986it [00:00, 40952.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 07:50:32,186 Dictionary created for label 'ner' with 5 values: LOC (seen 7140 times), PER (seen 6600 times), ORG (seen 6321 times), MISC (seen 3438 times)\n",
            "Dictionary with 5 tags: <unk>, LOC, PER, ORG, MISC\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "columns = {0 : 'text', 1:'pos', 2:'synctag', 3 : 'ner'}\n",
        "# directory where the data resides\n",
        "data_folder = '/content/'\n",
        "# initializing the corpus\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file = '/content/eng.train.txt',\n",
        "                              test_file = '/content/eng.testb.txt',\n",
        "                              dev_file = '/content/eng.train50000.txt')\n",
        "print(len(corpus.train))\n",
        "\n",
        "# tag to predict\n",
        "tag_type = 'ner'\n",
        "# make tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_label_dictionary(label_type=tag_type)\n",
        "print(tag_dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "PBQoOTLBhGlG",
        "outputId": "20180bbe-a7c5-436a-aac7-510d74a4dbe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 07:50:32,209 SequenceTagger predicts: Dictionary with 17 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# 7. start training\\ntrainer.train('/content/drive/MyDrive/NER/ner-flert-5e-5',\\n              learning_rate=5e-5,\\n              embeddings_storage_mode='none',\\n              mini_batch_size=4,\\n              max_epochs=50,\\n              write_weights = True,\\n              checkpoint=True)\\n\""
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from flair.trainers import ModelTrainer\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "# 5. initialize sequence tagger\n",
        "tagger = Bi_LSTM_CRF(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=tag_dictionary,\n",
        "                        dropout=0.5,\n",
        "                        tag_type=tag_type,\n",
        "                        use_crf=True)\n",
        "\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "\"\"\"\n",
        "# 7. start training\n",
        "trainer.train('/content/drive/MyDrive/NER/ner-flert-5e-5',\n",
        "              learning_rate=5e-5,\n",
        "              embeddings_storage_mode='none',\n",
        "              mini_batch_size=4,\n",
        "              max_epochs=50,\n",
        "              write_weights = True,\n",
        "              checkpoint=True)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXs-GvpQWoPw",
        "outputId": "a2fc354b-9fdc-46fd-a29d-074c12eed58f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 07:50:32,347 loading file /content/drive/MyDrive/NER/ner-flert-5e-5-resume4/checkpoint.pt\n",
            "2022-08-29 07:50:44,234 SequenceTagger predicts: Dictionary with 19 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/flair/trainers/trainer.py:65: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
            "  \"There should be no best model saved at epoch 1 except there \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 07:50:48,153 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 07:50:48,159 Model: \"Bi_LSTM_CRF(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): TransformerWordEmbeddings(\n",
            "      (model): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.25, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 1024)\n",
            "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.25, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 1024)\n",
            "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=2816, out_features=2816, bias=True)\n",
            "  (rnn): LSTM(\n",
            "    (lstm): LSTM(2816, 256, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-08-29 07:50:48,162 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 07:50:48,170 Corpus: \"Corpus: 14986 train + 3379 dev + 3683 test sentences\"\n",
            "2022-08-29 07:50:48,171 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 07:50:48,174 Parameters:\n",
            "2022-08-29 07:50:48,177  - learning_rate: \"0.000050\"\n",
            "2022-08-29 07:50:48,180  - mini_batch_size: \"4\"\n",
            "2022-08-29 07:50:48,181  - patience: \"3\"\n",
            "2022-08-29 07:50:48,184  - anneal_factor: \"0.5\"\n",
            "2022-08-29 07:50:48,187  - max_epochs: \"50\"\n",
            "2022-08-29 07:50:48,193  - shuffle: \"True\"\n",
            "2022-08-29 07:50:48,194  - train_with_dev: \"False\"\n",
            "2022-08-29 07:50:48,196  - batch_growth_annealing: \"False\"\n",
            "2022-08-29 07:50:48,197 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 07:50:48,199 Model training base path: \"/content/drive/MyDrive/NER/ner-flert-5e-5-resume5\"\n",
            "2022-08-29 07:50:48,201 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 07:50:48,203 Device: cuda:0\n",
            "2022-08-29 07:50:48,205 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 07:50:48,208 Embeddings storage mode: none\n",
            "2022-08-29 07:50:48,210 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 07:52:27,283 epoch 39 - iter 374/3747 - loss 0.12364297 - samples/sec: 15.11 - lr: 0.000050\n",
            "2022-08-29 07:54:10,258 epoch 39 - iter 748/3747 - loss 0.11877131 - samples/sec: 15.37 - lr: 0.000050\n",
            "2022-08-29 07:55:53,843 epoch 39 - iter 1122/3747 - loss 0.12100371 - samples/sec: 15.26 - lr: 0.000050\n",
            "2022-08-29 07:57:43,530 epoch 39 - iter 1496/3747 - loss 0.12056064 - samples/sec: 14.36 - lr: 0.000050\n",
            "2022-08-29 07:59:38,404 epoch 39 - iter 1870/3747 - loss 0.11897399 - samples/sec: 13.69 - lr: 0.000050\n",
            "2022-08-29 08:01:46,481 epoch 39 - iter 2244/3747 - loss 0.11953051 - samples/sec: 12.21 - lr: 0.000050\n",
            "2022-08-29 08:04:33,456 epoch 39 - iter 2618/3747 - loss 0.11955249 - samples/sec: 9.27 - lr: 0.000050\n",
            "2022-08-29 08:06:55,665 epoch 39 - iter 2992/3747 - loss 0.11863237 - samples/sec: 10.96 - lr: 0.000050\n",
            "2022-08-29 08:08:42,864 epoch 39 - iter 3366/3747 - loss 0.11779731 - samples/sec: 14.72 - lr: 0.000050\n",
            "2022-08-29 08:10:25,502 epoch 39 - iter 3740/3747 - loss 0.11852093 - samples/sec: 15.42 - lr: 0.000050\n",
            "2022-08-29 08:10:32,613 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 08:10:32,616 EPOCH 39 done: loss 0.1185 - lr 0.000050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 845/845 [02:20<00:00,  6.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 08:12:53,766 Evaluating as a multi-label problem: False\n",
            "2022-08-29 08:12:53,826 DEV : loss 0.06407283991575241 - f1-score (micro avg)  0.9241\n",
            "2022-08-29 08:12:53,910 BAD EPOCHS (no improvement): 0\n",
            "2022-08-29 08:13:05,107 saving best model\n",
            "2022-08-29 08:13:07,215 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 08:14:44,010 epoch 40 - iter 374/3747 - loss 0.11727912 - samples/sec: 15.46 - lr: 0.000050\n",
            "2022-08-29 08:16:24,298 epoch 40 - iter 748/3747 - loss 0.12082581 - samples/sec: 15.79 - lr: 0.000050\n",
            "2022-08-29 08:18:03,396 epoch 40 - iter 1122/3747 - loss 0.12015120 - samples/sec: 15.97 - lr: 0.000050\n",
            "2022-08-29 08:19:41,570 epoch 40 - iter 1496/3747 - loss 0.11912649 - samples/sec: 16.14 - lr: 0.000050\n",
            "2022-08-29 08:21:25,411 epoch 40 - iter 1870/3747 - loss 0.11715551 - samples/sec: 15.21 - lr: 0.000050\n",
            "2022-08-29 08:23:06,527 epoch 40 - iter 2244/3747 - loss 0.11750794 - samples/sec: 15.63 - lr: 0.000050\n",
            "2022-08-29 08:24:47,157 epoch 40 - iter 2618/3747 - loss 0.11695704 - samples/sec: 15.72 - lr: 0.000050\n",
            "2022-08-29 08:26:29,275 epoch 40 - iter 2992/3747 - loss 0.11696585 - samples/sec: 15.49 - lr: 0.000050\n",
            "2022-08-29 08:28:10,232 epoch 40 - iter 3366/3747 - loss 0.11704392 - samples/sec: 15.66 - lr: 0.000050\n",
            "2022-08-29 08:29:51,340 epoch 40 - iter 3740/3747 - loss 0.11710641 - samples/sec: 15.65 - lr: 0.000050\n",
            "2022-08-29 08:29:58,833 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 08:29:58,839 EPOCH 40 done: loss 0.1170 - lr 0.000050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 845/845 [02:21<00:00,  5.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 08:32:20,283 Evaluating as a multi-label problem: False\n",
            "2022-08-29 08:32:20,336 DEV : loss 0.061831433326005936 - f1-score (micro avg)  0.9266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 08:32:20,415 BAD EPOCHS (no improvement): 0\n",
            "2022-08-29 08:32:22,221 saving best model\n",
            "2022-08-29 08:32:24,465 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 08:34:02,242 epoch 41 - iter 374/3747 - loss 0.11973109 - samples/sec: 15.31 - lr: 0.000050\n",
            "2022-08-29 08:35:42,602 epoch 41 - iter 748/3747 - loss 0.11697762 - samples/sec: 15.79 - lr: 0.000050\n",
            "2022-08-29 08:37:21,123 epoch 41 - iter 1122/3747 - loss 0.11629036 - samples/sec: 16.08 - lr: 0.000050\n",
            "2022-08-29 08:39:01,374 epoch 41 - iter 1496/3747 - loss 0.11600552 - samples/sec: 15.82 - lr: 0.000050\n",
            "2022-08-29 08:40:42,911 epoch 41 - iter 1870/3747 - loss 0.11600616 - samples/sec: 15.57 - lr: 0.000050\n",
            "2022-08-29 08:42:21,668 epoch 41 - iter 2244/3747 - loss 0.11492731 - samples/sec: 16.04 - lr: 0.000050\n",
            "2022-08-29 08:44:01,164 epoch 41 - iter 2618/3747 - loss 0.11419172 - samples/sec: 15.91 - lr: 0.000050\n",
            "2022-08-29 08:45:42,700 epoch 41 - iter 2992/3747 - loss 0.11307277 - samples/sec: 15.57 - lr: 0.000050\n",
            "2022-08-29 08:47:22,435 epoch 41 - iter 3366/3747 - loss 0.11416950 - samples/sec: 15.87 - lr: 0.000050\n",
            "2022-08-29 08:49:41,289 epoch 41 - iter 3740/3747 - loss 0.11405555 - samples/sec: 11.21 - lr: 0.000050\n",
            "2022-08-29 08:49:48,718 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 08:49:48,722 EPOCH 41 done: loss 0.1140 - lr 0.000050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 845/845 [02:16<00:00,  6.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 08:52:05,324 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 08:52:05,379 DEV : loss 0.0597345195710659 - f1-score (micro avg)  0.9287\n",
            "2022-08-29 08:52:05,459 BAD EPOCHS (no improvement): 0\n",
            "2022-08-29 08:52:07,360 saving best model\n",
            "2022-08-29 08:52:09,919 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 08:53:45,263 epoch 42 - iter 374/3747 - loss 0.12577288 - samples/sec: 15.70 - lr: 0.000050\n",
            "2022-08-29 08:55:25,323 epoch 42 - iter 748/3747 - loss 0.11698299 - samples/sec: 15.82 - lr: 0.000050\n",
            "2022-08-29 08:57:09,494 epoch 42 - iter 1122/3747 - loss 0.11772367 - samples/sec: 15.19 - lr: 0.000050\n",
            "2022-08-29 08:58:50,492 epoch 42 - iter 1496/3747 - loss 0.11706390 - samples/sec: 15.67 - lr: 0.000050\n",
            "2022-08-29 09:00:31,176 epoch 42 - iter 1870/3747 - loss 0.11561110 - samples/sec: 15.71 - lr: 0.000050\n",
            "2022-08-29 09:02:10,270 epoch 42 - iter 2244/3747 - loss 0.11541507 - samples/sec: 16.00 - lr: 0.000050\n",
            "2022-08-29 09:03:49,163 epoch 42 - iter 2618/3747 - loss 0.11452114 - samples/sec: 16.01 - lr: 0.000050\n",
            "2022-08-29 09:05:30,105 epoch 42 - iter 2992/3747 - loss 0.11448135 - samples/sec: 15.66 - lr: 0.000050\n",
            "2022-08-29 09:07:09,189 epoch 42 - iter 3366/3747 - loss 0.11393113 - samples/sec: 15.99 - lr: 0.000050\n",
            "2022-08-29 09:08:47,698 epoch 42 - iter 3740/3747 - loss 0.11269409 - samples/sec: 16.08 - lr: 0.000050\n",
            "2022-08-29 09:08:54,877 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 09:08:54,878 EPOCH 42 done: loss 0.1127 - lr 0.000050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 845/845 [02:21<00:00,  5.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 09:11:16,159 Evaluating as a multi-label problem: False\n",
            "2022-08-29 09:11:16,214 DEV : loss 0.05776631459593773 - f1-score (micro avg)  0.9314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 09:11:16,299 BAD EPOCHS (no improvement): 0\n",
            "2022-08-29 09:11:18,124 saving best model\n",
            "2022-08-29 09:11:20,638 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 09:12:56,414 epoch 43 - iter 374/3747 - loss 0.10828719 - samples/sec: 15.63 - lr: 0.000050\n",
            "2022-08-29 09:14:37,849 epoch 43 - iter 748/3747 - loss 0.11095227 - samples/sec: 15.58 - lr: 0.000050\n",
            "2022-08-29 09:16:18,507 epoch 43 - iter 1122/3747 - loss 0.11069708 - samples/sec: 15.72 - lr: 0.000050\n",
            "2022-08-29 09:17:57,485 epoch 43 - iter 1496/3747 - loss 0.10994158 - samples/sec: 16.01 - lr: 0.000050\n",
            "2022-08-29 09:19:36,873 epoch 43 - iter 1870/3747 - loss 0.10970700 - samples/sec: 15.92 - lr: 0.000050\n",
            "2022-08-29 09:21:16,491 epoch 43 - iter 2244/3747 - loss 0.10934371 - samples/sec: 15.89 - lr: 0.000050\n",
            "2022-08-29 09:22:55,864 epoch 43 - iter 2618/3747 - loss 0.10898464 - samples/sec: 15.98 - lr: 0.000050\n",
            "2022-08-29 09:24:42,143 epoch 43 - iter 2992/3747 - loss 0.10989213 - samples/sec: 14.84 - lr: 0.000050\n",
            "2022-08-29 09:26:20,744 epoch 43 - iter 3366/3747 - loss 0.11007320 - samples/sec: 16.07 - lr: 0.000050\n",
            "2022-08-29 09:28:02,450 epoch 43 - iter 3740/3747 - loss 0.10982695 - samples/sec: 15.58 - lr: 0.000050\n",
            "2022-08-29 09:28:09,315 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 09:28:09,316 EPOCH 43 done: loss 0.1098 - lr 0.000050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 845/845 [02:16<00:00,  6.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 09:30:25,699 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 09:30:25,758 DEV : loss 0.05593200773000717 - f1-score (micro avg)  0.9334\n",
            "2022-08-29 09:30:25,842 BAD EPOCHS (no improvement): 0\n",
            "2022-08-29 09:30:27,875 saving best model\n",
            "2022-08-29 09:30:29,903 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 09:32:09,288 epoch 44 - iter 374/3747 - loss 0.10914649 - samples/sec: 15.06 - lr: 0.000050\n",
            "2022-08-29 09:33:48,753 epoch 44 - iter 748/3747 - loss 0.11131728 - samples/sec: 15.99 - lr: 0.000050\n",
            "2022-08-29 09:35:26,452 epoch 44 - iter 1122/3747 - loss 0.11125133 - samples/sec: 16.21 - lr: 0.000050\n",
            "2022-08-29 09:37:06,226 epoch 44 - iter 1496/3747 - loss 0.11255861 - samples/sec: 15.87 - lr: 0.000050\n",
            "2022-08-29 09:38:46,439 epoch 44 - iter 1870/3747 - loss 0.11044154 - samples/sec: 15.79 - lr: 0.000050\n",
            "2022-08-29 09:40:26,167 epoch 44 - iter 2244/3747 - loss 0.10983800 - samples/sec: 15.87 - lr: 0.000050\n",
            "2022-08-29 09:42:07,395 epoch 44 - iter 2618/3747 - loss 0.10997998 - samples/sec: 15.63 - lr: 0.000050\n",
            "2022-08-29 09:43:46,395 epoch 44 - iter 2992/3747 - loss 0.10868478 - samples/sec: 15.99 - lr: 0.000050\n",
            "2022-08-29 09:45:26,309 epoch 44 - iter 3366/3747 - loss 0.10954115 - samples/sec: 15.85 - lr: 0.000050\n",
            "2022-08-29 09:47:15,881 epoch 44 - iter 3740/3747 - loss 0.10861855 - samples/sec: 14.37 - lr: 0.000050\n",
            "2022-08-29 09:47:24,858 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 09:47:24,861 EPOCH 44 done: loss 0.1087 - lr 0.000050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 845/845 [04:07<00:00,  3.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 09:51:32,837 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 09:51:32,925 DEV : loss 0.05414774268865585 - f1-score (micro avg)  0.9356\n",
            "2022-08-29 09:51:33,047 BAD EPOCHS (no improvement): 0\n",
            "2022-08-29 09:51:35,510 saving best model\n",
            "2022-08-29 09:51:37,493 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 09:51:44,991 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 09:51:44,999 Exiting from training early.\n",
            "2022-08-29 09:51:45,000 Saving model ...\n",
            "2022-08-29 09:51:47,489 Done.\n",
            "2022-08-29 09:51:47,491 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 09:51:47,562 loading file /content/drive/MyDrive/NER/ner-flert-5e-5-resume5/best-model.pt\n",
            "2022-08-29 09:51:50,999 SequenceTagger predicts: Dictionary with 19 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 921/921 [02:31<00:00,  6.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 09:54:22,638 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 09:54:22,698 0.9401\t0.9313\t0.9356\t0.9272\n",
            "2022-08-29 09:54:22,701 \n",
            "Results:\n",
            "- F-score (micro) 0.9356\n",
            "- F-score (macro) 0.9272\n",
            "- Accuracy 0.9356\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ORG     0.9286    0.9393    0.9339      1661\n",
            "         LOC     0.9146    0.9213    0.9179      1668\n",
            "         PER     0.9616    0.9592    0.9604      1617\n",
            "        MISC     0.8958    0.8980    0.8968       702\n",
            "\n",
            "   micro avg     0.9401    0.9313    0.9356      5648\n",
            "   macro avg     0.9251    0.9294    0.9272      5648\n",
            "weighted avg     0.9249    0.9290    0.9247      5648\n",
            "\n",
            "2022-08-29 09:54:22,704 ----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "path= '/content/drive/MyDrive/NER/ner-flert-5e-5-resume'\n",
        "trained_model = Bi_LSTM_CRF.load(path + '4/checkpoint.pt')\n",
        "\n",
        "# resume training best model, but this time until epoch 25\n",
        "trainer.resume(trained_model,\n",
        "               base_path=path + '5',\n",
        "               max_epochs=50,\n",
        "               )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-4Nk2zR9bv5",
        "outputId": "b472e326-cdf2-4334-9e3c-97bafb0ff0c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-08-29 10:08:11,410 loading file /content/drive/MyDrive/NER/ner-flert-5e-5-resume5/checkpoint.pt\n",
            "2022-08-29 10:08:14,309 SequenceTagger predicts: Dictionary with 19 tags: O, S-LOC, B-LOC, E-LOC, I-LOC, S-PER, B-PER, E-PER, I-PER, S-ORG, B-ORG, E-ORG, I-ORG, S-MISC, B-MISC, E-MISC, I-MISC, <START>, <STOP>\n",
            "2022-08-29 10:08:14,681 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 10:08:14,689 Model: \"Bi_LSTM_CRF(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): TransformerWordEmbeddings(\n",
            "      (model): BertModel(\n",
            "        (embeddings): BertEmbeddings(\n",
            "          (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "          (position_embeddings): Embedding(512, 768)\n",
            "          (token_type_embeddings): Embedding(2, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (encoder): BertEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (6): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (7): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (8): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (9): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (10): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (11): BertLayer(\n",
            "              (attention): BertAttention(\n",
            "                (self): BertSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (output): BertSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): BertIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                (intermediate_act_fn): GELUActivation()\n",
            "              )\n",
            "              (output): BertOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (pooler): BertPooler(\n",
            "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (activation): Tanh()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.25, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 1024)\n",
            "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.25, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 1024)\n",
            "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=2816, out_features=2816, bias=True)\n",
            "  (rnn): LSTM(\n",
            "    (lstm): LSTM(2816, 256, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (linear): Linear(in_features=512, out_features=19, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-08-29 10:08:14,696 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 10:08:14,700 Corpus: \"Corpus: 14986 train + 3379 dev + 3683 test sentences\"\n",
            "2022-08-29 10:08:14,703 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 10:08:14,707 Parameters:\n",
            "2022-08-29 10:08:14,711  - learning_rate: \"0.000050\"\n",
            "2022-08-29 10:08:14,712  - mini_batch_size: \"4\"\n",
            "2022-08-29 10:08:14,718  - patience: \"3\"\n",
            "2022-08-29 10:08:14,721  - anneal_factor: \"0.5\"\n",
            "2022-08-29 10:08:14,723  - max_epochs: \"50\"\n",
            "2022-08-29 10:08:14,728  - shuffle: \"True\"\n",
            "2022-08-29 10:08:14,730  - train_with_dev: \"False\"\n",
            "2022-08-29 10:08:14,735  - batch_growth_annealing: \"False\"\n",
            "2022-08-29 10:08:14,742 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 10:08:14,746 Model training base path: \"/content/drive/MyDrive/NER/ner-flert-5e-5-resume6\"\n",
            "2022-08-29 10:08:14,750 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 10:08:14,753 Device: cuda:0\n",
            "2022-08-29 10:08:14,756 ----------------------------------------------------------------------------------------------------\n",
            "2022-08-29 10:08:14,757 Embeddings storage mode: none\n",
            "2022-08-29 10:08:14,770 ----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_model = Bi_LSTM_CRF.load(path + '5/checkpoint.pt')\n",
        "\n",
        "# resume training best model, but this time until epoch 25\n",
        "trainer.resume(trained_model,\n",
        "               base_path=path + '6',\n",
        "               max_epochs=50,\n",
        "               )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "ModelTrainer.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (windows store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "83d04032e859d7f6b4884d0eaea2daded37857bd69838437e04f68722128dc82"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0064395e0bf5463b9d7d60efbaba847b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02a4443c76704c11b9cfb711924f8d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04204f841327487ea5fc93b000af4406": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd583e5ecb9c4c68aec0a6daf4f59c2e",
              "IPY_MODEL_2d6f63ca55654fac83de65c9421c52e1",
              "IPY_MODEL_a3394f1ab4f04848afb93dc0a67f126c"
            ],
            "layout": "IPY_MODEL_fddde349fc6c44beb65aa7cd7f9681b8"
          }
        },
        "04745b1bbf8442238f95b92a55c78961": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0785c5838dfd4fc4b2e67c6771d0ef75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f4659d36cb6483abfc779e159df8370",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b95f5ce153ea427b91a6d5a843bc73c9",
            "value": 2
          }
        },
        "11eed811849847a6b0226a4a09281eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13a9103041ff41779e9c9eb094737faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea81ef14f82d4523ad27e5a36385bb5a",
            "placeholder": "​",
            "style": "IPY_MODEL_166a03674909478dace114b108b0328b",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "166a03674909478dace114b108b0328b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19f8c8a957a04f3b9e6a8761c4c2dbd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ac5e0cea9414703bcc8961206b0b23b",
              "IPY_MODEL_0785c5838dfd4fc4b2e67c6771d0ef75",
              "IPY_MODEL_ce42975c12054a9b8454d92b02036892"
            ],
            "layout": "IPY_MODEL_f324a6bd93814355984ac610902c684f"
          }
        },
        "1ad11bd99f2b4769bd09096f7a9f6540": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d7ad7fa0e5544fcb5bfccd4f2416c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c747ab66c2b443719f3c35a1a0651018",
              "IPY_MODEL_780070dcb8b44ad687833b42cf45fa0f",
              "IPY_MODEL_ef5b1b6f66344519989a43cd60440ae7"
            ],
            "layout": "IPY_MODEL_efa13989e75542dd952d45daa3e61e34"
          }
        },
        "1f82631f851049fe9d0e1d2c405a4178": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "292456e7e2bb48ebb0f2348a1039d42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa4e2db20c3d4bcf853afbe4fa401865",
            "placeholder": "​",
            "style": "IPY_MODEL_b78e38567a694c408e6599abf4e2d6e1",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "2d6f63ca55654fac83de65c9421c52e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a772497dcf4e477e8b81c1cd64f43e25",
            "max": 829,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e3be13e2cbe4370bf754910a078bd74",
            "value": 829
          }
        },
        "3531c31ab3514cb4abc743b59e5b2a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13a9103041ff41779e9c9eb094737faa",
              "IPY_MODEL_6eda3350421b4bdaafa4cd41d26679df",
              "IPY_MODEL_3cf712ed0ff1461b816b85e5adc0eca7"
            ],
            "layout": "IPY_MODEL_c415eeb4eb1443adaae056d85767508b"
          }
        },
        "35c11dd7d2594d55b7577a93a91c0560": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "363425048fc04711a8a9becdd25b4b56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382ef5bd06f94f3ca290e0e65d4b527b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3952eeec853c4eb1b60a6f21c5c8e899": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3ed9b070e946b5a17d3b5fbe57df3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c61fc754bc44e9296d39f21ac524a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cf712ed0ff1461b816b85e5adc0eca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9412e47775444a828762681bf92ea6ae",
            "placeholder": "​",
            "style": "IPY_MODEL_1f82631f851049fe9d0e1d2c405a4178",
            "value": " 208k/208k [00:00&lt;00:00, 251kB/s]"
          }
        },
        "4186ce2ba08b4d92865147b4c39f061e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b942b9a28834e74aa0adc6fcc14f2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11eed811849847a6b0226a4a09281eb4",
            "placeholder": "​",
            "style": "IPY_MODEL_8aeb65d1a2d34de4b6158790b00cda96",
            "value": " 413M/413M [00:07&lt;00:00, 56.4MB/s]"
          }
        },
        "521decf7ef104397bf24271871e20076": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5522ead4b6d34ebd8fee030981aa6199": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d45c582078b4c658adbecf8cf36cf26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ec8700ebd242a9bf703eeb7690e78e",
            "placeholder": "​",
            "style": "IPY_MODEL_02a4443c76704c11b9cfb711924f8d0d",
            "value": " 112/112 [00:00&lt;00:00, 3.21kB/s]"
          }
        },
        "68d47641f07d44dcb9d5e3ac6bf89661": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ab78ec85ae14d44b17eb3095bb93b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04745b1bbf8442238f95b92a55c78961",
            "placeholder": "​",
            "style": "IPY_MODEL_b1cf2cc291c84e7d9c3857becfd3dec2",
            "value": "Downloading special_tokens_map.json: 100%"
          }
        },
        "6eda3350421b4bdaafa4cd41d26679df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eeeb57619534e1c9b924511c4439191",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87301259f21b47c69a8a9847cbf68b3c",
            "value": 213450
          }
        },
        "70878c7ee8e34d44b14d9b6601f57811": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4186ce2ba08b4d92865147b4c39f061e",
            "max": 433316646,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ebdf85ea2a346d9a9e19d4a2765fe09",
            "value": 433316646
          }
        },
        "70e2ce7d826b4cc2aac3f2e603cba618": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a3fd4346e04db8b55d7eb54a6c52cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ab78ec85ae14d44b17eb3095bb93b8d",
              "IPY_MODEL_e5217e570a8f499cbe7f51149924488d",
              "IPY_MODEL_5d45c582078b4c658adbecf8cf36cf26"
            ],
            "layout": "IPY_MODEL_70e2ce7d826b4cc2aac3f2e603cba618"
          }
        },
        "780070dcb8b44ad687833b42cf45fa0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5522ead4b6d34ebd8fee030981aa6199",
            "max": 59,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ad11bd99f2b4769bd09096f7a9f6540",
            "value": 59
          }
        },
        "7a61a15189a3418fb42117eaaf98c104": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ebdf85ea2a346d9a9e19d4a2765fe09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f4659d36cb6483abfc779e159df8370": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8669047aeffa4f5f84b8cba7696910d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87301259f21b47c69a8a9847cbf68b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8aeb65d1a2d34de4b6158790b00cda96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eeeb57619534e1c9b924511c4439191": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9412e47775444a828762681bf92ea6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac5e0cea9414703bcc8961206b0b23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521decf7ef104397bf24271871e20076",
            "placeholder": "​",
            "style": "IPY_MODEL_35c11dd7d2594d55b7577a93a91c0560",
            "value": "Downloading added_tokens.json: 100%"
          }
        },
        "9e3be13e2cbe4370bf754910a078bd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3394f1ab4f04848afb93dc0a67f126c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8669047aeffa4f5f84b8cba7696910d8",
            "placeholder": "​",
            "style": "IPY_MODEL_7a61a15189a3418fb42117eaaf98c104",
            "value": " 829/829 [00:00&lt;00:00, 25.2kB/s]"
          }
        },
        "a772497dcf4e477e8b81c1cd64f43e25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1cf2cc291c84e7d9c3857becfd3dec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b59dfae24cdc401796d19c4671693652": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b78e38567a694c408e6599abf4e2d6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b95f5ce153ea427b91a6d5a843bc73c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb02eeaf646b41fe856a6ec7a62dd289": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c415eeb4eb1443adaae056d85767508b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c747ab66c2b443719f3c35a1a0651018": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3952eeec853c4eb1b60a6f21c5c8e899",
            "placeholder": "​",
            "style": "IPY_MODEL_0064395e0bf5463b9d7d60efbaba847b",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "ca0650497f6944beae48e538a27b26a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_292456e7e2bb48ebb0f2348a1039d42c",
              "IPY_MODEL_70878c7ee8e34d44b14d9b6601f57811",
              "IPY_MODEL_4b942b9a28834e74aa0adc6fcc14f2eb"
            ],
            "layout": "IPY_MODEL_ed8acdcf4c114bb89f801943d493ec53"
          }
        },
        "ce42975c12054a9b8454d92b02036892": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b59dfae24cdc401796d19c4671693652",
            "placeholder": "​",
            "style": "IPY_MODEL_68d47641f07d44dcb9d5e3ac6bf89661",
            "value": " 2.00/2.00 [00:00&lt;00:00, 54.2B/s]"
          }
        },
        "dd583e5ecb9c4c68aec0a6daf4f59c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc52c958796a4ba4b000a74522696ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_3c3ed9b070e946b5a17d3b5fbe57df3f",
            "value": "Downloading config.json: 100%"
          }
        },
        "e5217e570a8f499cbe7f51149924488d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_382ef5bd06f94f3ca290e0e65d4b527b",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb02eeaf646b41fe856a6ec7a62dd289",
            "value": 112
          }
        },
        "ea81ef14f82d4523ad27e5a36385bb5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed8acdcf4c114bb89f801943d493ec53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef5b1b6f66344519989a43cd60440ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_363425048fc04711a8a9becdd25b4b56",
            "placeholder": "​",
            "style": "IPY_MODEL_3c61fc754bc44e9296d39f21ac524a11",
            "value": " 59.0/59.0 [00:00&lt;00:00, 1.78kB/s]"
          }
        },
        "efa13989e75542dd952d45daa3e61e34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f324a6bd93814355984ac610902c684f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ec8700ebd242a9bf703eeb7690e78e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4e2db20c3d4bcf853afbe4fa401865": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc52c958796a4ba4b000a74522696ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fddde349fc6c44beb65aa7cd7f9681b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
