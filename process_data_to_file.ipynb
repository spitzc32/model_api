{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: genpipes in c:\\users\\jayra\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Jayra\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install genpipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize  \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"I-NAME\", \"I-PROFESSION\", \"I-LOCATION\", \"I-AGE\", \"I-DATE\", \"I-CONTACT\", \"I-ID\", \"I-PHI\",  \"O\"]\n",
    "class Tags():\n",
    "    def __init__(self):\n",
    "        self.entities = []\n",
    "        self.tags = []\n",
    "        self.sub_tags = [] \n",
    "    \n",
    "    def append_entity(self, entity: list):\n",
    "        self.entities.extend(entity)\n",
    "    \n",
    "    def append_tag(self, tag: list):\n",
    "        self.tags.extend(tag)\n",
    "    \n",
    "    def append_sub_tags(self, sub_tag: list):\n",
    "        self.sub_tags.extend(sub_tag)\n",
    "    \n",
    "\n",
    "def gather_tags(root):\n",
    "    entities = []\n",
    "    tags = []\n",
    "    sub_tags = []\n",
    "    for child in root.iter('TAGS'):\n",
    "        for subchild in child:\n",
    "            entity = subchild.get(\"text\").split(\" \")\n",
    "            [tags.append(subchild.tag) for ent in entity]\n",
    "            [sub_tags.append(subchild.get(\"TYPE\")) for ent in entity]\n",
    "            entities.extend(entity)\n",
    "    \n",
    "    tags.append(\"O\")\n",
    "    return entities, tags, sub_tags\n",
    "\n",
    "def split_to_sent(root):\n",
    "    doc_txt = str(root.find('TEXT').text)\n",
    "    tokens = sent_tokenize(doc_txt)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def split_to_tokens(text):\n",
    "    tokens = word_tokenize(text, preserve_line=True)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def label_txt(root):\n",
    "    new_tags = [\"I-NAME\", \"I-PROFESSION\", \"I-LOCATION\", \"I-AGE\", \"I-DATE\", \"I-CONTACT\", \"I-ID\", \"I-PHI\",  \"O\"]\n",
    "    orig_tags = [\"NAME\", \"PROFESSION\", \"LOCATION\", \"AGE\", \"DATE\", \"CONTACT\", \"ID\", \"PHI\", \"O\"]\n",
    "    entities, tags, sub_tags = gather_tags(root)\n",
    "    \n",
    "    sentences = split_to_sent(root)\n",
    "    ents, toks = [], []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = split_to_tokens(sentence)\n",
    "        for token in tokens:\n",
    "            idx = orig_tags.index(tags[entities.index(token) if token in entities else -1])\n",
    "            ents.append(token) \n",
    "            toks.append(new_tags[idx])\n",
    "\n",
    "        ents.append(\"\")\n",
    "        toks.append(\"\")\n",
    "    \n",
    "    return ents, toks\n",
    "\n",
    "     \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nner_tags_dev = Tags()\\nfor file in listOfFileDev:\\n    tree = ET.parse(f\"./data/test/{file}\")\\n    root = tree.getroot()\\n    label_txt(root, \"dev.txt\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfFile = os.listdir(\"./data/test/\")\n",
    "listOfFileDev = listOfFile[:len(listOfFile)//2]\n",
    "listOfFileTest = listOfFile[len(listOfFile)//2:]\n",
    "\"\"\"\n",
    "ner_tags_dev = Tags()\n",
    "for file in listOfFileDev:\n",
    "    tree = ET.parse(f\"./data/test/{file}\")\n",
    "    root = tree.getroot()\n",
    "    label_txt(root, \"dev.txt\")\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0           1\n",
      "0           Record           O\n",
      "1             date           O\n",
      "2                :           O\n",
      "3       2077-03-31      I-DATE\n",
      "4            Notre  I-LOCATION\n",
      "...            ...         ...\n",
      "206265           4           O\n",
      "206266      Beeper           O\n",
      "206267           #           O\n",
      "206268       07736   I-CONTACT\n",
      "206269                        \n",
      "\n",
      "[206270 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ner_tags = Tags()\n",
    "for file in listOfFileTest:\n",
    "    tree = ET.parse(f\"./data/test/{file}\")\n",
    "    root = tree.getroot()\n",
    "    label_txt(root, \"test.txt\")\"\"\"\n",
    "\n",
    "listOfFile = os.listdir(\"./data/test/\")\n",
    "listOfFileDev = listOfFile[:len(listOfFile)//2]\n",
    "listOfFileTest = listOfFile[len(listOfFile)//2:]\n",
    "\n",
    "entities, tokens = [], []\n",
    "for file in listOfFileTest:\n",
    "    tree = ET.parse(f\"./data/test/{file}\")\n",
    "    root = tree.getroot()\n",
    "    ents, toks = label_txt(root)\n",
    "    entities.extend(ents)\n",
    "    tokens.extend(toks) \n",
    "\n",
    "new_tokens = [entities, tokens]\n",
    "df = pd.DataFrame(new_tokens).transpose()\n",
    "print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.txt\", sep=\" \", index=False, columns=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83d04032e859d7f6b4884d0eaea2daded37857bd69838437e04f68722128dc82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
